<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Professor Noli Brazil" />

<meta name="date" content="2024-05-29" />

<title>Kriging</title>

<script src="site_libs/header-attrs-2.22/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
      .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">GEO 200CN: Spring 2024</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="syllabus.html">Syllabus</a>
</li>
<li>
  <a href="hw_guidelines.html">Assignment Guidelines</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Labs
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="getting_started.html">Getting Started</a>
    </li>
    <li>
      <a href="eda.html">Exploratory Data Analysis</a>
    </li>
    <li>
      <a href="inference.html">Statistical Inference</a>
    </li>
    <li>
      <a href="hypothesis.html">Hypothesis Testing</a>
    </li>
    <li>
      <a href="linearregression.html">Linear Regression</a>
    </li>
    <li>
      <a href="linearregression2.html">More Linear Regression</a>
    </li>
    <li>
      <a href="logistic.html">Logistic Regression</a>
    </li>
    <li>
      <a href="introspatial.html">Intro to Spatial Data</a>
    </li>
    <li>
      <a href="pointpatterns.html">Point Pattern Analysis</a>
    </li>
    <li>
      <a href="spatialautocorrelation.html">Spatial Autocorrelation</a>
    </li>
    <li>
      <a href="spatialreg.html">Spatial Regression</a>
    </li>
    <li>
      <a href="prediction.html">Prediction Modelling</a>
    </li>
    <li>
      <a href="variableselection.html">Variable Selection</a>
    </li>
    <li>
      <a href="interpolation.html">Spatial Interpolation</a>
    </li>
    <li>
      <a href="kriging.html">Kriging</a>
    </li>
    <li>
      <a href="regtrees.html">Regression Trees</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Other
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="tips.html">R Tips</a>
    </li>
    <li>
      <a href="data_wrangling.html">Data Wrangling</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Kriging</h1>
<h3 class="subtitle"><font size="4">GEO 200CN - Quantitative
Geography</font></h3>
<h4 class="author">Professor Noli Brazil</h4>
<h4 class="date">May 29, 2024</h4>

</div>


<style>
p.comment {
background-color: #DBDBDB;
padding: 10px;
border: 1px solid black;
margin-left: 25px;
border-radius: 5px;
font-style: normal;
}

.figure {
   margin-top: 20px;
   margin-bottom: 20px;
}

h1.title {
  font-weight: bold;
  font-family: Arial;  
}

h2.title {
  font-family: Arial;  
}

</style>
<style type="text/css">
#TOC {
  font-size: 13px;
  font-family: Arial;
}
</style>
<p><br />
</p>
<p>In the last lab guide, we went through deterministic methods for
interpolating spatial data. In this lab guide, we go through
probabilistic or geostatistical spatial interpolation methods. We’ll
focus on two popular geostatistical procedures: trend surface analysis
and Kriging. This lab guide closely follows OSU Ch. 10. The objectives
of this lab are as follows</p>
<ol style="list-style-type: decimal">
<li>Learn how to run a trend surface analysis</li>
<li>Learn how to estimate a variogram</li>
<li>Learn how to interpolate values using Ordinary Kriging</li>
<li>Learn how to interpolate values using Universal Kriging</li>
</ol>
<p>To help us accomplish these learning objectives, we will use
California Air Pollution data. Ground-level ozone is the main component
of smog and is the single most widespread air pollutant in the United
States. The objective is to spatially interpolate ozone levels in
California. After learning how to run trend surface and Kriging methods
on California data, you will make comparisons between deterministic and
geostatistical methods using Texas data. Lab material has been adapted
from <a
href="https://rspatial.org/analysis/4-interpolation.html">Spatial Data
Science</a>.</p>
<div style="margin-bottom:25px;">

</div>
<div id="installing-and-loading-packages" class="section level2">
<h2><strong>Installing and loading packages</strong></h2>
<p><br />
</p>
<p>No new packages this lab. Load all necessary packages using
<code>library()</code>.</p>
<pre class="r"><code>library(sf)
library(gstat)
library(tidyverse)
library(tmap)
library(dismo)
library(terra)</code></pre>
<div style="margin-bottom:25px;">

</div>
</div>
<div id="bringing-in-the-data" class="section level2">
<h2><strong>Bringing in the data</strong></h2>
<p><br />
</p>
<p>We will use the <a href="https://ww3.arb.ca.gov/html/ds.htm">airqual
dataset</a> to interpolate <a
href="https://oehha.ca.gov/calenviroscreen/indicator/air-quality-ozone">ozone</a>
levels for California (averages for 1980-2009). Download the file
<em>kriging.zip</em> from Canvas in the Week 9 Lab and Assignment
folder. It contains all the files that will be used in this guide. Bring
in the file <em>airqual.shp</em>, which contains ozone levels (among
many other variables, which we will not use) for control points
scattered throughout California. We’ll keep spatial objects in
<strong>sf</strong> form since many of the kriging functions work with
them.</p>
<pre class="r"><code>aq &lt;- st_read(&quot;airquality.shp&quot;)</code></pre>
<p>Next, we need to create a template raster to interpolate to. We will
interpolate across California, so bring in the file
<em>counties.shp</em> as an <strong>sf</strong> object.</p>
<pre class="r"><code>ca &lt;- st_read(&quot;counties.shp&quot;)</code></pre>
<p>Let’s plot the points on CA to see what we got. We’ll use our long
time friend <code>ggplot()</code></p>
<pre class="r"><code>ggplot(data = ca) +
  geom_sf() +
  geom_sf(data = aq, color = &quot;red&quot;)</code></pre>
<p><img
src="kriging_files/figure-html/unnamed-chunk-4-1.png" /><!-- --></p>
<p><em>aq</em> is an <em>sf</em> object, but we’ll need a regular data
frame for some of the functions we’ll use to interpolate the data. We
use the function <code>st_drop_geometry()</code> to turn <em>aq</em>
into a regular data frame.</p>
<pre class="r"><code>x &lt;- aq %&gt;% 
  st_drop_geometry()

class(x)</code></pre>
<pre><code>## [1] &quot;data.frame&quot;</code></pre>
<p>To create the template raster for interpolation, coerce the
<em>sf</em> object of California, <em>ca</em>, to a raster using the
function <code>rast</code>()`.</p>
<pre class="r"><code>r &lt;- rast(ca)
res(r) &lt;- 10  # 10 km if your CRS&#39;s units are in km</code></pre>
<p>We’re now ready to interpolate!</p>
<div style="margin-bottom:25px;">

</div>
</div>
<div id="trend-surface-analysis" class="section level2">
<h2><strong>Trend surface analysis</strong></h2>
<p><br />
</p>
<p>OSU begins Chapter 10 discussing trend surface analysis. Trend
surface modeling is basically a regression of the variable you want to
interpolate on the spatial coordinates of your observed locations. We’ve
already done regression before! So, trend surface analysis in regression
lingo characterizes the outcome as the variable we want to interpolate
<em>OZDLYAV</em>, and the independent variables as the X (longitude) and
Y (latitude) coordinates. This is equation 10.3 in OSU and the book
calls it a linear trend surface.</p>
<p>Let’s run the model using our friend <code>glm()</code>.</p>
<pre class="r"><code>reg.ols &lt;- glm(OZDLYAV~x + y, 
               data=aq)</code></pre>
<p>And here is a summary.</p>
<pre class="r"><code>summary(reg.ols)</code></pre>
<pre><code>## 
## Call:
## glm(formula = OZDLYAV ~ x + y, data = aq)
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 32.883735   0.672214  48.919  &lt; 2e-16 ***
## x            0.044224   0.004008  11.034  &lt; 2e-16 ***
## y            0.018565   0.003012   6.164 1.58e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 78.33922)
## 
##     Null deviance: 47042  on 451  degrees of freedom
## Residual deviance: 35174  on 449  degrees of freedom
## AIC: 3258.9
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<p>Let’s use this model to interpolate across California. Instead of
working off the <em>glm</em> model we created above, we can utilize the
suite of geostatistical functions available in the package
<strong>gstat</strong>. The package provides <a
href="https://cran.r-project.org/web/packages/gstat/index.html">basic
functionality</a> for univariable and multivariable geostatistical
analysis. We were introduced to <strong>gstat</strong> in the <a
href="https://geo200cn.github.io/interpolation.html#Local_Spatial_Average">last
lab</a>. We’ll use the function <code>gstat()</code> to run a linear
trend surface model.</p>
<pre class="r"><code>lm.1 &lt;- gstat(formula=OZDLYAV~1, 
              locations=~x+y, 
              degree=1, 
              data=x)</code></pre>
<p>The argument <code>formula=OZDLYAV~1</code> tells the function to
base the interpolation of <em>OZDLYAV</em> only on the location
coordinates. The argument <code>locations=~x+y</code> define the spatial
data locations (coordinates), where <em>x</em> and <em>y</em> are the
variable names for the longitude and latitude. The argument
<code>degree=</code> establishes a first order trend. Notice that for
<code>data</code>, we use the regular data frame <em>x</em> because
<code>gstat()</code> does not work well with <em>sf</em> objects.</p>
<p>Were interpolating across the California raster template <em>r</em>,
so we use the <code>interpolate()</code> function from the
<strong>terra</strong> package.</p>
<pre class="r"><code>r.m  &lt;- interpolate(r, lm.1, debug.level=0)</code></pre>
<p>We then need to clip the interpolate raster to CA boundaries.</p>
<pre class="r"><code>r.m &lt;- mask(r.m, ca)</code></pre>
<p>Finally, we plot</p>
<pre class="r"><code>plot(r.m, 1)</code></pre>
<p><img
src="kriging_files/figure-html/unnamed-chunk-12-1.png" /><!-- --></p>
<p>We can also use <code>ggplot()</code>, noting that the interpolated
values are stored in the variable <em>var1.pred</em></p>
<pre class="r"><code>names(r.m)</code></pre>
<pre><code>## [1] &quot;var1.pred&quot; &quot;var1.var&quot;</code></pre>
<pre class="r"><code># Plot the map
ggplot(as.data.frame(r.m, xy = TRUE)) +
  geom_raster(aes(x = x, y = y, fill = var1.pred)) +
    labs(fill = &quot;Predicted ozone&quot;) +
    scale_fill_gradient(low= &quot;white&quot;, high = &quot;red&quot;, na.value =&quot;gray&quot;) </code></pre>
<p><img
src="kriging_files/figure-html/unnamed-chunk-13-1.png" /><!-- --></p>
<p>Let’s try another trend. The second order surface polynomial (aka
quadratic polynomial) is a parabolic surface whose equation is given by
the one shown on page 286 in OSU. We use <code>gstat()</code> again, but
change <code>degree</code> to 2.</p>
<pre class="r"><code>lm.2 &lt;- gstat(formula=OZDLYAV~1, 
              locations=~x+y, 
              degree=2, 
              data=x)</code></pre>
<p>Interpolate this across California’s grid and map.</p>
<pre class="r"><code># Use the regression model output to interpolate the surface
r.m2  &lt;- interpolate(r, lm.2, debug.level=0)

# Clip the interpolated raster to CA
r.m2 &lt;- mask(r.m2, ca)</code></pre>
<p>Map the interpolated values</p>
<pre class="r"><code>#plot
plot(r.m2, 1)</code></pre>
<p><img
src="kriging_files/figure-html/unnamed-chunk-16-1.png" /><!-- --></p>
<p>Using <code>ggplot()</code></p>
<pre class="r"><code>ggplot(as.data.frame(r.m2, xy = TRUE)) +
  geom_raster(aes(x = x, y = y, fill = var1.pred)) +
      labs(fill = &quot;Predicted ozone&quot;) +
    scale_fill_gradient(low= &quot;white&quot;, high = &quot;red&quot;, na.value =&quot;gray&quot;) </code></pre>
<p><img
src="kriging_files/figure-html/unnamed-chunk-17-1.png" /><!-- --></p>
<p>This interpolation picks up a slight curvature in the east-west
trend.</p>
<div style="margin-bottom:25px;">

</div>
</div>
<div id="kriging" class="section level2">
<h2><strong>Kriging</strong></h2>
<p><br />
</p>
<p>OSU calls trend surface analysis “dumb” on page 287. How mean! So,
they then turn to Kriging. Kriging interpolates by calculating the
weighted average of known values of the neighborhood points.</p>
<p>There are many flavors of kriging. These flavors are described on
pages 310-311 in OSU. The most common form of kriging is ordinary
kriging. Ordinary kriging assumes stationarity: the mean and variance of
the values is constant across the spatial field. OSU describes on page
295 the three steps to interpolate values using kriging.</p>
<ol style="list-style-type: decimal">
<li>Produce a description of the spatial variation in the sample control
point data</li>
<li>Summarize this spatial variation by a regular mathematical
function</li>
<li>Use this model to determine interpolation weights</li>
</ol>
<p>Let’s go through each step.</p>
<div style="margin-bottom:25px;">

</div>
<div id="describe-the-spatial-variation" class="section level3">
<h3><strong>Describe the Spatial Variation</strong></h3>
<p><br />
</p>
<p>This step involves estimating the (semi) variogram. The variogram is
the foundation of geostatistical analysis and is a measure of the
variance as a function of distance. Basically, the variogram is our
model of spatial autocorrelation. Let’s estimate a variogram for
<em>OZDLYAV</em>.</p>
<p>First, let’s create a variogram cloud. A variogram cloud
characterizes the spatial autocorrelation across a surface that we have
sampled at a set of control points. The variogram cloud is obtained by
plotting all possible squared differences of observation pairs against
their separation distance. As any point in the variogram cloud refers to
a pair of points in the data set, the variogram cloud is used to point
us to areas with unusual high or low variability. We use the
<code>variogram()</code> function, which calculates the sample
variogram. Here, we set the lag <em>h</em> to be 20 km through the
<code>width</code> argument.</p>
<pre class="r"><code>vcloud &lt;- variogram(OZDLYAV~1, locations=aq, width=20, cloud = TRUE)</code></pre>
<p>Notice that <code>variogram()</code> is <strong>sf</strong> friendly,
so we use the <em>aq</em> object.</p>
<p>The first argument <code>OZDLYAV~1</code> specifies the response
variable (what you are interpolating) and what covariates the
interpolation will be based on. Ordinary kriging relies only on
distance, which is reflected by the formula <code>OZDLYAV~1</code>, and
assumes a constant trend (or a stationary process) for the variable. The
ordinary kriging predictor is a weighted average of the surrounding
observations, where the weight depends on a fitted model to the measured
points, the distance to the prediction location, and the spatial
relationships among the measured values around the prediction
location.</p>
<p>We then plot the cloud, getting a plot like Figure 10.7 in OSU.</p>
<pre class="r"><code>plot(vcloud)</code></pre>
<p><img
src="kriging_files/figure-html/unnamed-chunk-19-1.png" /><!-- --></p>
<p>The variogram cloud gives us some insight, but need to simplify it a
bit. This is when we turn to the sample variogram. The sample variogram
is estimated using the function <code>variogram()</code> but without the
argument <code>cloud = TRUE</code>.</p>
<pre class="r"><code>v.o &lt;- variogram(OZDLYAV~1, locations=aq, width=20)
plot(v.o)</code></pre>
<p><img
src="kriging_files/figure-html/unnamed-chunk-20-1.png" /><!-- --></p>
<p>The variogram plot is nothing but a plot of averages of semivariogram
cloud values over distance intervals. It is like Figure 10.9 in OSU.</p>
<p>The generated variogram is isotropic, meaning that we are assuming
there is a constant trend for the variable. In other words, the spatial
variability is the same in all directions. We will examine the situation
where there is an apparent spatial trend later in this lab when we
discuss universal kriging.</p>
<div style="margin-bottom:25px;">

</div>
</div>
<div id="fit-the-model-variogram" class="section level3">
<h3><strong>Fit the model variogram</strong></h3>
<p><br />
</p>
<p>The variogram we constructed is the sample variogram. It is for the
observed or sampled points. In order to estimate values at unknown
locations, we need to create a model variogram. To generate a model
variogram, we need to estimate the following components</p>
<ol style="list-style-type: decimal">
<li>Sill</li>
<li>Range</li>
<li>Nugget</li>
</ol>
<p>The sample variogram we created above can help us estimate these
values. We need to eyeball the values from the sample variogram plot.
The sill is the y-value where there is no more spatial correlation, the
point on the graph where y-values level off, which is around 100. The
range is the x-value where the variogram reaches the sill which appears
to occur at around 150. The nugget can be thought of as the y-axis
intercept, which occurs at an approximate value of 30. We don’t need to
get these values exactly correct. We just need to plug reasonable values
into the function as starting points. From these starting points, R will
then adjust the values to optimize model fit.</p>
<p>You also need to establish the theoretical function that determines
the influence of near and far locations on the estimation. Common
functions include exponential circular, spherical and Gaussian (see
Figure 10.10 in OSU for the shapes). You can check the available models
by typing in <code>vgm()</code> in your console. We’ll start out with
the Exponential function <code>Exp</code>.</p>
<p>We use the <code>fit.variogram()</code> function to fit a model
variogram. The first argument specifies the empirical or sample
variogram. The second argument is the model, with parameters, to be fit
to the sample variogram. The model specifies the sill
<code>psill =</code>, the range <code>range =</code>, the nugget
<code>nugget =</code> and the theoretical model <code>model =</code>.
Plug in the values we eyeballed from the sample variogram as starting
points for the model. <code>fit.variogram</code> will help optimize the
fit of the model using an iterative weighted least squares (IWLS)
method.</p>
<pre class="r"><code>fve.o &lt;- fit.variogram(v.o, model = vgm(psill = 100, model = &quot;Exp&quot;, range = 150, nugget = 30))</code></pre>
<p>The estimating method (IWLS) seeks to optimize the parameters (but
conditioned on their starting values which we plug in). Here are the
actual parameters that R used to fit the model</p>
<pre class="r"><code>fve.o</code></pre>
<pre><code>##   model    psill    range
## 1   Nug 21.96589  0.00000
## 2   Exp 85.52938 72.31329</code></pre>
<p>With the sample and fit variogram, one can plot them together to see
how well the fit was:</p>
<pre class="r"><code>plot(variogramLine(fve.o, 400), type=&#39;l&#39;, ylim=c(0,120), col=&#39;blue&#39;, main = &#39;Exponential variogram model&#39;)
points(v.o[,2:3], pch=20, col=&#39;red&#39;)</code></pre>
<p><img
src="kriging_files/figure-html/unnamed-chunk-23-1.png" /><!-- --></p>
<p>Here’s another way to plot the variogram and the model.</p>
<pre class="r"><code>plot(v.o, fve.o, main = &#39;Exponential variogram model&#39;)</code></pre>
<p><img
src="kriging_files/figure-html/unnamed-chunk-24-1.png" /><!-- --></p>
<p>Let’s try a different function (spherical <code>Sph</code> instead of
exponential)</p>
<pre class="r"><code>fvs.o &lt;- fit.variogram(v.o, model = vgm(psill = 100, model = &quot;Sph&quot;, range = 150, nugget = 30))
fvs.o</code></pre>
<pre><code>##   model    psill   range
## 1   Nug 25.59723   0.000
## 2   Sph 72.69835 136.131</code></pre>
<pre class="r"><code>plot(variogramLine(fvs.o, 400), type=&#39;l&#39;, ylim=c(0,120) ,col=&#39;blue&#39;, lwd=2, main = &#39;Spherical variogram model&#39;)
points(v.o[,2:3], pch=20, col=&#39;red&#39;)</code></pre>
<p><img
src="kriging_files/figure-html/unnamed-chunk-25-1.png" /><!-- --></p>
<p>Both look pretty good in this case. What about Gaussian
<code>Gau</code>?</p>
<pre class="r"><code>fvg.o &lt;- fit.variogram(v.o, model = vgm(psill = 100, model = &quot;Gau&quot;, range = 150, nugget = 30))
fvg.o</code></pre>
<pre><code>##   model    psill    range
## 1   Nug 32.45995  0.00000
## 2   Gau 63.75329 58.51846</code></pre>
<pre class="r"><code>plot(variogramLine(fvg.o, 400), type=&#39;l&#39;, ylim=c(0,120) ,col=&#39;blue&#39;, lwd=2, main = &#39;Gaussian variogram model&#39;)
points(v.o[,2:3], pch=20, col=&#39;red&#39;)</code></pre>
<p><img
src="kriging_files/figure-html/unnamed-chunk-26-1.png" /><!-- --></p>
<div style="margin-bottom:25px;">

</div>
</div>
<div id="ordinary-kriging" class="section level3">
<h3><strong>Ordinary kriging</strong></h3>
<p><br />
</p>
<p>Once we have determined an appropriate variogram model we can
interpolate across California. Ordinary kriging is an interpolation
method that uses weighted averages of all,or a defined set of
neighboring observations. To Krig, you always need to establish the
fitted variogram, because the variogram establishes the weights in the
interpolation. See OSU pages 302-306 if you are interested in seeing the
math of how Ordinary Kriging is done. To employ Kriging in R, use the
function <code>gstat()</code>.</p>
<pre class="r"><code>k.o &lt;- gstat(formula = OZDLYAV~1, 
             locations = ~x+y, 
             data = x, 
             model=fve.o)</code></pre>
<p>The first argument is our interpolation formula, second are our
observed points, third is our data, and fourth is the variogram model we
are using to interpolate, in this case the exponential model
<em>fve.o</em>.</p>
<p>Next, we need to predict or interpolate for our grid <em>r</em>.</p>
<pre class="r"><code>kp.o  &lt;- interpolate(r, k.o, debug.level=0)</code></pre>
<p>Let’s plot the predicted values.</p>
<pre class="r"><code># Convert kriged surface to a raster object for clipping
ok.o &lt;- mask(kp.o, ca)
plot(ok.o, 1)</code></pre>
<p><img
src="kriging_files/figure-html/unnamed-chunk-29-1.png" /><!-- --></p>
<p>Using <code>ggplot()</code></p>
<pre class="r"><code>ggplot(as.data.frame(ok.o, xy = TRUE)) +
  geom_raster(aes(x = x, y = y, fill = var1.pred)) +
      labs(fill = &quot;Predicted ozone&quot;) +
    scale_fill_gradient(low= &quot;white&quot;, high = &quot;red&quot;, na.value =&quot;gray&quot;) </code></pre>
<p><img
src="kriging_files/figure-html/unnamed-chunk-30-1.png" /><!-- --></p>
<p>How good are our predictions? We run 5-fold cross-validation to
estimate the test prediction error. First, we establish the
<code>RMSE()</code> function we created <a
href="https://geo200cn.github.io/interpolation.html#mean_model">last lab
guide</a>.</p>
<pre class="r"><code>RMSE &lt;- function(observed, predicted) {
  sqrt(mean((predicted - observed)^2, na.rm=TRUE))
}</code></pre>
<p>Then run 5-fold cross validation using the same for loop from <a
href="https://geo200cn.github.io/interpolation#mean_model.html#proximity_polygons">last
lab guide</a></p>
<pre class="r"><code>set.seed(1234)
kf &lt;- kfold(nrow(aq))
rmseok &lt;- rep(NA, 5)
for (k in 1:5) {
  test &lt;- aq[kf == k, ]
  train &lt;- aq[kf != k, ]
  gscv &lt;- gstat(formula = OZDLYAV~1, locations = train, model=fve.o)
  p &lt;- predict(gscv, newdata = test, debug.level=0)$var1.pred
  rmseok[k] &lt;- RMSE(test$OZDLYAV, p)
}</code></pre>
<p>We get 5 RMSEs for each fold</p>
<pre class="r"><code>rmseok</code></pre>
<pre><code>## [1] 5.967864 6.973699 6.667093 8.863368 6.195943</code></pre>
<p>What is our 5-fold root mean squared error?</p>
<pre class="r"><code>mean(rmseok)</code></pre>
<pre><code>## [1] 6.933593</code></pre>
<div style="margin-bottom:25px;">

</div>
</div>
</div>
<div id="universal-kriging" class="section level2">
<h2><strong>Universal kriging</strong></h2>
<p><br />
</p>
<p>While in Ordinary Kriging it is assumed that the mean is constant
across the entire region of study (second order stationarity), in
Universal Kriging the mean is a function of the site coordinates. This
means we believe there is a trend. Instead of <code>OZDLYAV~1</code> in
our formula, we use <code>OZDLYAV~x + y</code>, which accounts for the x
and y coordinates of each point in the prediction.</p>
<p>Following the same sequence as above in ordinary kriging , we get the
empirical or sample variogram.</p>
<pre class="r"><code>v.u &lt;- variogram(OZDLYAV~x + y, locations=aq, width=20)
plot(v.u)</code></pre>
<p><img
src="kriging_files/figure-html/unnamed-chunk-35-1.png" /><!-- --></p>
<p>Sill looks like 75 (ish), range is 90 (ish), and nugget is 30 (ish).
We now get the variogram model using the exponential function.</p>
<pre class="r"><code>fve.u &lt;- fit.variogram(v.u, model = vgm(psill = 75, model = &quot;Exp&quot;, range = 90, nugget = 30))</code></pre>
<p>Now, we krige</p>
<pre class="r"><code>k.u &lt;- gstat(formula = OZDLYAV~x + y, 
             locations = ~x+y, 
             data = x, 
             model=fve.u)</code></pre>
<p>Predict</p>
<pre class="r"><code>kp.u  &lt;- interpolate(r, k.u, debug.level=0)</code></pre>
<p>Plot the predictions to see what they look like</p>
<pre class="r"><code># Convert kriged surface to a raster object for clipping
ok.u &lt;- mask(kp.u, ca)
plot(ok.u, 1)</code></pre>
<p><img
src="kriging_files/figure-html/unnamed-chunk-39-1.png" /><!-- --></p>
<p>Using <code>ggplot()</code></p>
<pre class="r"><code>ggplot(as.data.frame(ok.u, xy = TRUE)) +
  geom_raster(aes(x = x, y = y, fill = var1.pred)) +
      labs(fill = &quot;Predicted ozone&quot;) +
    scale_fill_gradient(low= &quot;white&quot;, high = &quot;red&quot;, na.value =&quot;gray&quot;) </code></pre>
<p><img
src="kriging_files/figure-html/unnamed-chunk-40-1.png" /><!-- --></p>
<p>And the 5-fold RMSE is</p>
<pre class="r"><code>rmseuk &lt;- rep(NA, 5)
for (k in 1:5) {
  test &lt;- aq[kf == k, ]
  train &lt;- aq[kf != k, ]
  gscv &lt;- gstat(formula = OZDLYAV~x + y, locations = train, model=fve.u)
  p &lt;- predict(gscv, newdata = test, debug.level=0)$var1.pred
  rmseuk[k] &lt;- RMSE(test$OZDLYAV, p)
}
mean(rmseuk)</code></pre>
<pre><code>## [1] 7.084023</code></pre>
<div style="margin-bottom:25px;">

</div>
</div>
<div id="comparing-methods" class="section level2">
<h2><strong>Comparing methods</strong></h2>
<p><br />
</p>
<p>Kriging is one of the most common interpolation methods in a
Geographer’s toolkit. But, it’s not the only tool. In fact, we went
through several in last lab guide. Let’s go back to these and make some
comparisons with the new friends we made in today’s lab.</p>
<p>You must be tired of running models on California. Let’s predict
precipitation for the great state of Texas! Bring in the files
<em>precip</em> and <em>texas</em>.</p>
<pre class="r"><code>P &lt;- st_read(&quot;precip.shp&quot;)
TX &lt;- st_read(&quot;texas.shp&quot;)</code></pre>
<p>You will be interpolating the variable <em>Precip_in</em> in the
<em>P</em> data set, which is average precipitation in inches for
several meteorological sites in Texas. Let’s map the samples cases.</p>
<pre class="r"><code>ggplot(data = TX) +
  geom_sf() +
    geom_sf(data = P, color = &quot;red&quot;)</code></pre>
<p><img
src="kriging_files/figure-html/unnamed-chunk-43-1.png" /><!-- --></p>
<p>We need to convert <em>TX</em> to a raster to create a grid template
like we did above with California.</p>
<pre class="r"><code>r &lt;- rast(TX)
res(r) &lt;- 10</code></pre>
<p>Now, you’re ready to interpolate.</p>
<p><br></p>
<p class="comment">
<strong>Question 1</strong>: Run the local spatial average method using
3-nearest neighbors to interpolate Texas precipitation levels across the
state.
</p>
<p class="comment">
<strong>Question 2</strong>: Run the inverse distance weighted (IDW)
method.
</p>
<p class="comment">
<strong>Question 3</strong>: Run a quadratic polynomial trend surface
model.
</p>
<p class="comment">
<strong>Question 4</strong>: Run universal kriging. Hint: Don’t just
copy and paste the code from the California case. Texas is different
from California, so the parameters will be different. In particular,
play around with the <code>cutoff =</code> and <code>width =</code>
values when you create the sample variogram. The cutoff represents the
maximal spatial distance taken into account between two observations.
The width is the lag or distance interval over which the semi-variance
is calculated. You want to make sure you can see enough of the variogram
top to bottom and left to right to estimate the sill, range and nugget.
</p>
<p class="comment">
<strong>Question 5</strong>: Use 5-fold cross-validation to determine
which of the four methods is the best based on RMSE.
</p>
<p class="comment">
<strong>Question 6</strong>: Map the interpolated values for the best
model.
</p>
<p class="comment">
<strong>Question 7</strong>: Show where the largest difference exist
between IDW and the quadratic trend model.
</p>
<p><br></p>
<p>And we’re done!</p>
<hr />
<p><a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc/4.0/88x31.png" /></a><br />This
work is licensed under a
<a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/">Creative
Commons Attribution-NonCommercial 4.0 International License</a>.</p>
<p>Website created and maintained by <a
href="https://nbrazil.faculty.ucdavis.edu/">Noli Brazil</a></p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3,h4",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>


</body>
</html>
