<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Professor Noli Brazil" />

<meta name="date" content="2024-05-15" />

<title>Prediction Modelling</title>

<script src="site_libs/header-attrs-2.22/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
      .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">GEO 200CN: Spring 2024</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="syllabus.html">Syllabus</a>
</li>
<li>
  <a href="hw_guidelines.html">Assignment Guidelines</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Labs
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="getting_started.html">Getting Started</a>
    </li>
    <li>
      <a href="eda.html">Exploratory Data Analysis</a>
    </li>
    <li>
      <a href="inference.html">Statistical Inference</a>
    </li>
    <li>
      <a href="hypothesis.html">Hypothesis Testing</a>
    </li>
    <li>
      <a href="linearregression.html">Linear Regression</a>
    </li>
    <li>
      <a href="linearregression2.html">More Linear Regression</a>
    </li>
    <li>
      <a href="logistic.html">Logistic Regression</a>
    </li>
    <li>
      <a href="introspatial.html">Intro to Spatial Data</a>
    </li>
    <li>
      <a href="pointpatterns.html">Point Pattern Analysis</a>
    </li>
    <li>
      <a href="spatialautocorrelation.html">Spatial Autocorrelation</a>
    </li>
    <li>
      <a href="spatialreg.html">Spatial Regression</a>
    </li>
    <li>
      <a href="prediction.html">Prediction Modelling</a>
    </li>
    <li>
      <a href="variableselection.html">Variable Selection</a>
    </li>
    <li>
      <a href="interpolation.html">Spatial Interpolation</a>
    </li>
    <li>
      <a href="kriging.html">Kriging</a>
    </li>
    <li>
      <a href="regtrees.html">Regression Trees</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Other
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="tips.html">R Tips</a>
    </li>
    <li>
      <a href="data_wrangling.html">Data Wrangling</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Prediction Modelling</h1>
<h3 class="subtitle"><font size="4">GEO 200CN - Quantitative
Geography</font></h3>
<h4 class="author">Professor Noli Brazil</h4>
<h4 class="date">May 15, 2024</h4>

</div>


<style>
p.comment {
background-color: #DBDBDB;
padding: 10px;
border: 1px solid black;
margin-left: 25px;
border-radius: 5px;
font-style: normal;
}

.figure {
   margin-top: 20px;
   margin-bottom: 20px;
}

h1.title {
  font-weight: bold;
  font-family: Arial;  
}

h2.title {
  font-family: Arial;  
}

</style>
<style type="text/css">
#TOC {
  font-size: 13px;
  font-family: Arial;
}
</style>
<p><br />
</p>
<p>In class so far, we’ve learned how to use regression models mostly
within the context of description and inference. Starting in this lab,
we will learn how to employ regression (and quantitative tools more
generally) for predictive purposes. Specifically, the objectives of this
lab are as follows</p>
<ol style="list-style-type: decimal">
<li>Learn how to use regression in a prediction framework</li>
<li>Learn about testing and training your data</li>
<li>Learn how to run cross validation to calculate test error rates</li>
</ol>
<p>To help us accomplish these learning objectives, we will use
temperature data for California weather stations to predict a numeric
outcome (temperature) and data from the <a
href="https://www.cdc.gov/brfss/index.html">Behavioral Risk Factor
Surveillance System</a> (BRFSS), an annual survey conducted by the
Centers for Disease Control and Prevention to predict a binary outcome
(fair/poor health or not). The lab follows closely this week’s readings
in ISLR.</p>
<div style="margin-bottom:25px;">

</div>
<div id="installing-and-loading-packages" class="section level2">
<h2><strong>Installing and loading packages</strong></h2>
<p><br />
</p>
<p>We’ll be using two new packages in this lab. First, install them if
you haven’t already.</p>
<pre class="r"><code>install.packages(c(&quot;dismo&quot;, &quot;boot&quot;))</code></pre>
<p>Next load them and the other packages we need using
<code>library()</code>.</p>
<pre class="r"><code>library(dismo)
library(boot)
library(sf)
library(tidyverse)</code></pre>
<div style="margin-bottom:25px;">

</div>
</div>
<div id="bring-in-the-data" class="section level2">
<h2><strong>Bring in the data</strong></h2>
<p><br />
</p>
<p>Download the data for this lab guide from Canvas in the Week 7 Labs
and Assignment folder. All the data are zipped into the file
<em>prediction.zip</em>. First, bring in the BRFSS file
<em>brfss16.csv</em> file into R.</p>
<pre class="r"><code>brfss16 &lt;- read_csv(&quot;brfss16.csv&quot;)</code></pre>
<p>The BRFSS is an annual survey that collects state data about U.S.
residents regarding their health-related risk behaviors, chronic health
conditions, and use of preventive services. The data contain individuals
as units of observations. The main goal of the analysis is to examine
characteristics that help predict self-reported bad health, where bad
health is an indicator of whether the respondent reported “yes” to the
question: “In general, would you say that in general your health is
Fair/Poor?” Our dependent variable is <em>badhealth</em> and our
independent variables are age <em>agec</em>, gender <em>male</em>,
educational attainment <em>educ</em>, race/ethnicity <em>race_eth</em>,
whether the individual indicates they <em>smoke</em>, employment status
<em>employ</em>, marital status <em>marst</em>, body mass index
<em>bmi</em> and income <em>inc</em>. A record layout of the data can be
found <a
href="https://raw.githubusercontent.com/geo200cn/data/master/brfss16RL.txt">here</a></p>
<p>Next, bring in the California temperature dataset
<em>temperature.csv</em></p>
<pre class="r"><code>ca.temp &lt;- read_csv(&quot;temperature.csv&quot;)</code></pre>
<p>The file contains the average monthly temperature in Celsius. We need
to do some data prep before we can start using this data set. Let’s
create a new variable that represents the mean monthly temperature,
which will be our response variable, using the function
<code>rowMeans()</code>.</p>
<pre class="r"><code>ca.temp &lt;- ca.temp %&gt;%
            mutate(temp = rowMeans(dplyr::select(ca.temp, JAN:DEC)))</code></pre>
<p>Let’s map the stations so we can visualize their geographic locations
across the state. We have longitude and latitude. First, we need to
convert <em>ca.temp</em> into a spatial <strong>sf</strong> object.
Here, we use the function <code>st_as_sf()</code> and use an appropriate
<a
href="https://www.nceas.ucsb.edu/sites/default/files/2020-04/OverviewCoordinateReferenceSystems.pdf">coordinate
reference system</a>.</p>
<pre class="r"><code>ca.temp.sf &lt;- ca.temp %&gt;%
          st_as_sf(coords = c(&quot;LONG&quot;, &quot;LAT&quot;), 
                   crs =&quot;+proj=longlat +datum=NAD83 +ellps=GRS80&quot;)</code></pre>
<p>Let’s then bring in a California counties layer.</p>
<pre class="r"><code>cacounties &lt;- st_read(&quot;counties_2000.shp&quot;)</code></pre>
<p>Next, we need to transform both layers to a planar CRS (Teale Albers
in this case) to assure that the computations we perform later are OK.
That is, we want to avoid interpreting angles as if they were planar
coordinates. We’ll use the <code>st_transform()</code> function to
reproject each <strong>sf</strong> object into the appropriate CRS.</p>
<pre class="r"><code>TA &lt;- crs(&quot; +proj=aea +lat_1=34 +lat_2=40.5 +lat_0=0 +lon_0=-120 +x_0=0
+y_0=-4000000 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0&quot;)

ca.temp.sf&lt;- st_transform(ca.temp.sf, TA)
cacounties&lt;- st_transform(cacounties, TA)</code></pre>
<pre class="r"><code>st_crs(ca.temp.sf) == st_crs(cacounties)</code></pre>
<pre><code>## [1] TRUE</code></pre>
<p>Finally, map the stations by their mean monthly temperature.</p>
<pre class="r"><code>ggplot(data = cacounties) +geom_sf() +
          geom_sf(data = ca.temp.sf, aes(color = temp)) +
      scale_color_gradient(low = &quot;blue&quot;, high = &quot;red&quot;, name =&quot;Temperature&quot;) + 
    theme( axis.text =  element_blank(),
    axis.ticks =  element_blank(),
    panel.background = element_blank())</code></pre>
<p><img
src="prediction_files/figure-html/unnamed-chunk-10-1.png" /><!-- --></p>
<p>Now on to the modelling!!</p>
<div style="margin-bottom:25px;">

</div>
</div>
<div id="classification" class="section level2">
<h2><strong>Classification</strong></h2>
<p><br />
</p>
<p>As discussed in the introduction to this lab guide, we’re now
entering the phase of the class where we go from using models and
methods to <em>describe</em> and <em>infer</em> to those that
<em>predict</em>. In the prediction world, we’re primarily concerned
about the quality of our predictions rather than trying to describe a
relationship or infer causality. In other words, we create a model to
predict a phenomena and then test whether our model does a good job of
predicting that phenomena.</p>
<p>In the case of a binary outcome, we are trying to predict whether an
observation belongs in one class or another. For example, predicting
whether a person will report they’re in poor/fair health or not. We
learned about logistic regression, which handles binary outcomes, in <a
href="https://geo200cn.github.io/logistic.html">a prior lab</a>. For a
logistic regression model or any model that has a categorical outcome
variable, prediction is known as classification.</p>
<p>First, let’s run a multiple logistic regression predicting the
variable reporting Fair/Poor health (yes or 1) or not (no or 0)
<em>badhealth</em>.</p>
<pre class="r"><code>logit.fit &lt;- glm(badhealth ~ bmi + race_eth + agec + male + smoke + educ + inc + 
                   employ + marst , 
                 family = binomial, 
                 data = brfss16)</code></pre>
<p>Next, we predict the probability of reporting bad health for the
367,873 observations in our original data. We use the
<code>predict()</code> function.</p>
<pre class="r"><code>pfit &lt;- predict(logit.fit, type = &quot;response&quot;)</code></pre>
<p>Here, we are not predicting for a new set of observations, but rather
for our original 367,873 observations. In other words, <em>pfit</em>
contains the fitted values based on the model <em>logit.fit</em>.</p>
<p>Remember that our original variable is a 0, 1 variable - “not bad
health”, “bad health.” So, we now need to convert the probabilities into
one of these categories. What is typically done is if the predicted
probability is greater than 0.5, designate it a 1 (“bad health”). We do
so in the following code using the <code>ifelse()</code> command. We
save the classification back into the data set using
<code>mutate()</code>.</p>
<pre class="r"><code>brfss16 &lt;- brfss16 %&gt;%
            mutate(pprob = pfit, 
                   pclass = ifelse(pprob &gt; 0.5, 1, 0))</code></pre>
<p>The first argument in the <code>mutate</code> command saves the
vector of predicted probabilities. The second argument creates a
variable that transforms to 1 all of the probabilities that are greater
than 0.5, and 0 otherwise.</p>
<p>Did the model do a good job predicting bad health status? In
practice, a binary classifier can make two types of errors: it can
incorrectly assign an individual who is in bad health, or it can
incorrectly assign an individual who is not in bad health. A simple
approach to assessing the prediction quality of a classification model
is to examine a confusion matrix, which is discussed in ISLR page 145.
We use the <code>table()</code> function to produce a confusion matrix
of our logistic regression predictions.</p>
<pre class="r"><code>table(brfss16$pclass, brfss16$badhealth)</code></pre>
<pre><code>##    
##          0      1
##   0 290051  48782
##   1   9813  19227</code></pre>
<p>The diagonal elements of the confusion matrix indicate correct
predictions, while the off-diagonals represent incorrect predictions.
Hence our model correctly predicted non bad health status for 290,051
persons and bad health status for 19,227 persons, for a total of 309,278
correct predictions. In this case, logistic regression correctly
predicted the health status of 84.1% individuals.</p>
<p>Is the model better at predicting health status compared to an OLS
regression model? We run an OLS using the same variables.</p>
<pre class="r"><code>ols.fit &lt;- glm(badhealth ~ bmi + race_eth + agec + male + smoke + educ + inc + 
                 employ + marst , 
               family = gaussian, 
               data = brfss16)</code></pre>
<p><br></p>
<p class="comment">
<strong>Question 1</strong>: Create the confusion matrix for the OLS
model <em>ols.fit</em>. What percent of predictions did the OLS model
get correct?
</p>
<p><br></p>
<div style="margin-bottom:25px;">

</div>
</div>
<div id="training-and-testing" class="section level2">
<h2><strong>Training and Testing</strong></h2>
<p><br />
</p>
<p>It looks like our model does a good job predicting bad health status.
However, the results are misleading because we trained and tested the
model on the same set of 367,873 observations. The training error rate
is typically overly optimistic - it tends to underestimate the test
error rate.</p>
<p>In order to better assess the accuracy of the logistic regression
model, we can fit the model using new data. We can do this two ways.
First, we can use (or train) part of the original data to create our
model, and then examine how well it predicts the held out (test) data.
This will yield a more realistic error rate, in the sense that in
practice we will be interested in our model’s performance not on the
data that we used to fit the model.</p>
<p>We’ll first need to get a sample of the original data to train on.
How much to sample? The literature is not clear. Let’s set aside 25% of
the data to test, and train the rest. We use the the tidy friendly
<code>sample_frac()</code> to sample 75% of the data to train. We use
<code>set.seed()</code> to give us a pseudorandom set of numbers to
replicate the results (i.e., if I run this code again with the same seed
number, I should get the same results).</p>
<pre class="r"><code>set.seed(1234)
brfss16$id &lt;- 1:nrow(brfss16)
#75% of data are used to train the model
train &lt;- brfss16 %&gt;% dplyr::sample_frac(.75)
#25% of data are used to test the model predictions
test  &lt;- anti_join(brfss16, train, by = &#39;id&#39;)</code></pre>
<p>Now run the logistic regression model on the training data set.</p>
<pre class="r"><code>logit.train.fit &lt;- glm(badhealth ~ bmi + race_eth + agec + male + smoke + educ + 
                         inc + employ + marst , 
                       family = binomial, 
                       data = train)</code></pre>
<p>Take a look at the results.</p>
<pre class="r"><code>summary(logit.train.fit)</code></pre>
<pre><code>## 
## Call:
## glm(formula = badhealth ~ bmi + race_eth + agec + male + smoke + 
##     educ + inc + employ + marst, family = binomial, data = train)
## 
## Coefficients:
##                       Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)          -1.878760   0.062852 -29.892  &lt; 2e-16 ***
## bmi                   0.054633   0.000863  63.304  &lt; 2e-16 ***
## race_ethnh black     -0.414729   0.026493 -15.654  &lt; 2e-16 ***
## race_ethnh multirace -0.104400   0.040498  -2.578 0.009940 ** 
## race_ethnh other     -0.247123   0.032811  -7.532 5.01e-14 ***
## race_ethnhwhite      -0.485699   0.020462 -23.736  &lt; 2e-16 ***
## agec(24,39]           0.366907   0.040023   9.167  &lt; 2e-16 ***
## agec(39,59]           0.823166   0.038986  21.114  &lt; 2e-16 ***
## agec(59,79]           0.959662   0.040258  23.838  &lt; 2e-16 ***
## agec(79,99]           1.312480   0.044473  29.512  &lt; 2e-16 ***
## maleMale              0.092994   0.011796   7.883 3.19e-15 ***
## smokeFormer          -0.308237   0.016591 -18.579  &lt; 2e-16 ***
## smokeNeverSmoked     -0.609946   0.015802 -38.599  &lt; 2e-16 ***
## educ1somehs          -0.267665   0.036181  -7.398 1.38e-13 ***
## educ2hsgrad          -0.598346   0.031903 -18.755  &lt; 2e-16 ***
## educ3somecol         -0.720753   0.032464 -22.202  &lt; 2e-16 ***
## educ4colgrad         -1.028077   0.033348 -30.829  &lt; 2e-16 ***
## inc                  -0.279518   0.004751 -58.831  &lt; 2e-16 ***
## employnilf            0.539075   0.019129  28.182  &lt; 2e-16 ***
## employretired         0.629023   0.017071  36.847  &lt; 2e-16 ***
## employunable          2.127378   0.019817 107.353  &lt; 2e-16 ***
## marstdivorced        -0.025365   0.035883  -0.707 0.479631    
## marstmarried         -0.086159   0.034296  -2.512 0.011998 *  
## marstnm              -0.141429   0.036171  -3.910 9.23e-05 ***
## marstseparated        0.143162   0.046700   3.066 0.002172 ** 
## marstwidowed         -0.134139   0.037267  -3.599 0.000319 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 264392  on 275904  degrees of freedom
## Residual deviance: 210224  on 275879  degrees of freedom
## AIC: 210276
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>Then predict probabilities using the <em>test</em> data set by adding
the argument <code>newdata =</code></p>
<pre class="r"><code>pfit2 &lt;- predict(logit.train.fit, newdata = test, type = &quot;response&quot;)</code></pre>
<p>Confusion matrix time.</p>
<pre class="r"><code>test &lt;- test %&gt;%
          mutate(pprob = pfit2, pclass = ifelse(pprob &gt; 0.5, 1, 0))</code></pre>
<pre class="r"><code>table(test$pclass, test$badhealth)</code></pre>
<pre><code>##    
##         0     1
##   0 72579 12068
##   1  2468  4853</code></pre>
<p>The test error rate is 15.8, not far from the 15.9 training error
rate calculated above.</p>
<p>The second way to test the predictive quality of your model is to
model past data to predict future data. The file <em>brfss17.csv</em>
contains individual data from the the 2017 version of the BRFSS. The
data file contains the same exact variables as the 2016 file you have
been using in this lab. Bring this data set into R.</p>
<p><br></p>
<p class="comment">
<strong>Question 2</strong>: Calculate the test error rate using the
2017 BRFSS data for the prediction model <em>logit.train.fit</em>.
</p>
<div style="margin-bottom:25px;">

</div>
</div>
<div id="cross-validation" class="section level2">
<h2><strong>Cross-Validation</strong></h2>
<p><br />
</p>
<p>With the BRFSS example, we have the fortune of having “future”
observations to test our model. Everyone is not that lucky. One way to
getting test error rates without a test data set is to run
cross-validation, which is covered in ISLR starting on page 176. To
demonstrate cross validation, let’s turn to the CA temperature data.</p>
<p>The goal is to create a model that predicts temperature, which is a
continuous numeric variable. We first run a linear regression model with
no independent variables (known as a null model). Such a model uses the
mean annual temperature across the stations as an estimator of
temperature at every location.</p>
<pre class="r"><code>null &lt;- lm(temp ~ 1, data = ca.temp.sf)</code></pre>
<p>Save the predicted values (which is just the mean) and the residuals
(observed - predicted) into our data frame. The function
<code>predict()</code> gives us the predicted values and the function
<code>resid()</code> gives us the residuals.</p>
<pre class="r"><code>ca.temp.sf &lt;- ca.temp.sf %&gt;%
            mutate(nullpred = predict(null), 
                   nullresid = resid(null))</code></pre>
<p>And we make a map of the residuals.</p>
<pre class="r"><code>ggplot(data = cacounties) +geom_sf() +
          geom_sf(data = ca.temp.sf, aes(color = nullresid)) +
    scale_color_gradient(low = &quot;blue&quot;, high = &quot;red&quot;, name =&quot;Residual&quot;) + 
    theme( axis.text =  element_blank(),
    axis.ticks =  element_blank(),
    panel.background = element_blank())</code></pre>
<p><img
src="prediction_files/figure-html/unnamed-chunk-24-1.png" /><!-- --></p>
<p>This does not look very good. There are large differences. Moreover,
there is some spatial autocorrelation in the residuals, indicating that
some places have better predictions than others.</p>
<p>Because we are now in prediction land, we are very concerned about
fit. Instead of the error rate, the Root Mean Squared Error (RMSE) is
used to measure fit when your outcome is continuous numeric.</p>
<p>Let’s define an RMSE function so we can compute RMSE for all the
models we run in this lab.</p>
<p><br></p>
<p class="comment">
<strong>Question 3</strong>: Create a function called <em>RMSE</em> that
calculates the root mean squared error for a model’s predictions. The
inputs should be the observed values and the predicted values from the
model. The output should be one value representing the RMSE. Your
function should look something like below
</p>
<pre class="r"><code>RMSE &lt;- function(observed, predicted) {
#Calculate the RMSE
}</code></pre>
<p class="comment">
<strong>Question 4</strong>: What is the RMSE of the null model for
predicting temperature?
</p>
<p><br></p>
<div style="margin-bottom:25px;">

</div>
<div id="k-fold-cross-validation" class="section level3">
<h3><strong>k-fold Cross-Validation</strong></h3>
<p><br />
</p>
<p>We can probably do better than use the mean to predict temperature.
Let’s try a linear regression model with independent variables. The only
meaningful attribute we have in our <em>ca.temp.sf</em> dataset is the
geographic coordinates, i.e. the location of each weather station. A
regression of any variable on geographic coordinates is known as a trend
surface model, which we’ll cover in more detail next week (Ch. 9 in
OSU). But, for now, let’s regress temperature on a station’s longitude
and latitude. Let’s also compute an error rate using k-cross
validation.</p>
<p>We first need to cut up the data set into <em>k</em> sets. Let’s set
<em>k</em> = 10. We can use the function <code>kfold()</code>, which is
a part of the <strong>dismo</strong> package, to conveniently partition
our data into <em>k</em> folds. For replication purposes, I
<code>set.seed()</code> because <code>kfold()</code> randomly partitions
the data set. Make sure to use this seed for your assignment.</p>
<pre class="r"><code>set.seed(5162016)
k &lt;- kfold(ca.temp.sf, k = 10)
table(k)</code></pre>
<pre><code>## k
##  1  2  3  4  5  6  7  8  9 10 
## 30 30 31 30 30 30 30 31 30 30</code></pre>
<p>The output shows that 30 observations are in the test set of the
first fold, 30 different observations are in the second fold, 31
different observations are in the third fold, and so on. Let’s visualize
what we have done for one fold (k = 1):</p>
<pre class="r"><code>test &lt;- ca.temp.sf[k==1, ]
train &lt;- ca.temp.sf[k!=1, ]

ggplot(data = cacounties) +geom_sf() +
          geom_sf(data = train, aes(color = &quot;blue&quot;), show.legend = &quot;point&quot;) +
          geom_sf(data = test, aes(color = &quot;red&quot;), show.legend = &quot;point&quot;)  +
    scale_color_manual(labels = c(&quot;model training&quot;, &quot;model testing&quot;), 
                       values = c(&quot;blue&quot;, &quot;red&quot;), name = &quot;&quot;) +
    theme( axis.text =  element_blank(),
    axis.ticks =  element_blank(),
    panel.background = element_blank())</code></pre>
<p><img
src="prediction_files/figure-html/unnamed-chunk-28-1.png" /><!-- --></p>
<p>Let’s run a linear regression on our first fold. First, save the
coordinates and temperature into a single data frame.</p>
<pre class="r"><code>df &lt;- data.frame(st_coordinates(train), temp=train$temp)</code></pre>
<p>Then fit a linear regression model to these data. We’ll use
<code>glm()</code>.</p>
<pre class="r"><code>m &lt;- glm(temp ~ X+Y, data=df)
summary(m)</code></pre>
<pre><code>## 
## Call:
## glm(formula = temp ~ X + Y, data = df)
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  1.390e+01  1.984e-01  70.055  &lt; 2e-16 ***
## X            5.125e-07  1.428e-06   0.359     0.72    
## Y           -8.464e-06  1.025e-06  -8.257  6.8e-15 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 7.891022)
## 
##     Null deviance: 3803.0  on 271  degrees of freedom
## Residual deviance: 2122.7  on 269  degrees of freedom
## AIC: 1338.8
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<p><br></p>
<p class="comment">
<strong>Question 5</strong>: According to this model, how much does the
temperature in California change if you travel 500 miles to the north?
</p>
<p><br></p>
<p>We can now estimate temperature values for our hold-out (test)
sample</p>
<pre class="r"><code>v &lt;- data.frame(st_coordinates(test))
p &lt;- predict(m, v)
#First several predictions
head(p)</code></pre>
<pre><code>##        1        2        3        4        5        6 
## 18.49892 17.27353 17.99420 16.04129 13.71275 12.06281</code></pre>
<p>And then evaluate the results by comparing them with the known values
for these locations using the <code>RMSE()</code> function we created
above.</p>
<p><br></p>
<p class="comment">
<strong>Question 6</strong>: What is the RMSE of the linear regression
model predicting temperature? Did the linear regression model improve
upon the null model?
</p>
<p><br></p>
<p>We did this for one fold. But, we have to do this for all 10 folds.
We can accomplish this by running our friend the <code>for()</code>
loop. Here, we plug in the <code>RMSE()</code> function that we created
above. Carefully go through (and comment) each line of code so that you
understand what is being done here.</p>
<pre class="r"><code>r &lt;- rep(NA,5)
for (i in 1:10) {
  test &lt;- ca.temp.sf[k==i, ]
  train &lt;- ca.temp.sf[k!=i, ]
  df &lt;- data.frame(st_coordinates(train), temp=train$temp)
  m &lt;- glm(temp ~ ., data=df)
  v &lt;- data.frame(st_coordinates(test))
  p &lt;- predict(m, v)
  r[i] &lt;- RMSE(p, test$temp)
}</code></pre>
<p>The result is the RMSE for each of the 10 folds.</p>
<pre class="r"><code>r</code></pre>
<pre><code>##  [1] 3.289749 2.248640 3.043732 3.422114 2.533438 2.819896 2.794843 2.838339
##  [9] 3.011162 2.470722</code></pre>
<p>We then calculate the average, which is equation 5.3 shown on ISLR
page 181 (we show the RMSE, ISLR shows the MSE, the only difference
being MSE is squared).</p>
<pre class="r"><code>mean(r)</code></pre>
<pre><code>## [1] 2.847263</code></pre>
<p>The model is not great, but it did capture something, and it is
better than the null model.</p>
<div style="margin-bottom:25px;">

</div>
</div>
<div id="leave-one-out-cross-validation" class="section level3">
<h3><strong>Leave-One-Out Cross-Validation</strong></h3>
<p><br />
</p>
<p>We did the <em>k</em>-fold cross-validation technique. Now do the
leave-one-out cross-validation technique described in this week’s
reading. You can create a for loop like the one we created above for
k-fold CV, or you can use the function <code>cv.glm()</code>, which is a
part of the <strong>boot</strong> package. If you use
<code>cv.glm()</code>, make sure to use the RMSE function we created
above as a part of the cost. Also you don’t need to separate the data
set into training and test data sets as <code>cv.glm()</code> will
automatically do that for you.</p>
<p>You can save the coordinates and the temperature for the entire set
of locations in a data frame</p>
<pre class="r"><code>df2 &lt;- data.frame(st_coordinates(ca.temp.sf), temp = ca.temp.sf$temp)</code></pre>
<p>and go from there.</p>
<p><br></p>
<p class="comment">
<strong>Question 7</strong>: What is the RMSE using leave-one-out cross
validation?
</p>
<p><br></p>
<hr />
<p><a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc/4.0/88x31.png" /></a><br />This
work is licensed under a
<a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/">Creative
Commons Attribution-NonCommercial 4.0 International License</a>.</p>
<p>Website created and maintained by <a
href="https://nbrazil.faculty.ucdavis.edu/">Noli Brazil</a></p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3,h4",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>


</body>
</html>
