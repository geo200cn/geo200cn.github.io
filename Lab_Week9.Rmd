---
title: "Lab Lecture 9"
author: "Kenji Tomari"
output: 
  html_document:
    theme: readable
    toc: true
    toc_depth: 3
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Raster

## Readings

These are for reference, and not required. However, if you find yourself thinking you'll work with such things as orthophotos (i.e. satellite photos) or some other field data, I would recommend reading through the sections on {raster} in greater detail.

* [Summary](https://rspatial.org/raster/spatial/2-spatialdata.html#raster-data)
* [Data Format](https://rspatial.org/raster/spatial/4-rasterdata.html)
* [Reading & Writing](https://rspatial.org/raster/spatial/5-files.html#raster-files)
* [Projection & Transformation](https://rspatial.org/raster/spatial/6-crs.html#transforming-raster-data)
* [Data Manipulation](https://rspatial.org/raster/spatial/8-rastermanip.html)
* [Maps](https://rspatial.org/raster/spatial/9-maps.html#raster)

# Interpolation Lab

## Question 1

You should be able to comment most of this code chunk fairly simply by comparing it to last week's lab. However, I think the last line of code is perhaps more difficult to directly interpret: essentially, we're making a comparison between our proximity polygons model and mean model. Strictly speaking, it is a fraction by which our proximity polygon model performs better than the mean (null) model. This [answer](https://stats.stackexchange.com/questions/218418/comparing-rmse-to-model#answer-218493) on stackexchange seems to discuss this measure of comparison between a test model and a null model. It suggests that it's similar to R^2 (but that it isn't R^2 strictly speaking).

## Question 2

Compare the RMSE values.

Sidebar: Did you know Proximity Polygons are also known by the name **Nearest Neighbor Interpolation**?

## Question 3

See OSU p. 254.

## Question 4

In answering this question you might pay attention to the very first map we made with `spplot(dsp, 'prec', cuts=cuts, col.regions=blues(5), sp.layout=pols, pch=20, cex=2)`. Notice where the control points are, and where they are not located. Here's also some code as a hint (run it!): `mean(dta@data$prec)`.

> "It is important to notice that the IDW interpolation method also has some disadvantages: the quality of the interpolation result can decrease, if the distribution of sample data points is uneven." ([QGIS](https://docs.qgis.org/2.8/en/docs/gentle_gis_introduction/spatial_analysis_interpolation.html#inverse-distance-weighted-idw))

## Question 5

Hint: Look in the documentation on {gstat} to understand the arguments we haven't come across yet, like `nmax`. You can use this code to read the documentation: `?gstat::gstat`. Understanding `set` is a bit more complicated from the documentation, and its less relevant for answering this question[^1]. So, if `nmax = 1`, how many control points are each predicted point relying upon? You should compare the map produced here with the previous maps we've produced to ascertain the proper name of this model.

[^1]: Here, you have to read the [gstat standalone guide](http://www.gstat.org/gstat.pdf). On p. 40 it begins to describe what the `set` argument takes in as its' values. In short, `idp` is the power function *k* of equation 9.9 in OSU p. 260. (FYI, The funky symbol in 9.9 that looks like an truncated infinity symbol is read as "proportional to".) By default, the idp is set to 2 (as indicated with most computer programs in OSU p260). Again, however, `set` in this question is less important than `nmax`.

# Kriging

## Introduction

Before diving into the interpolation technique known as Kriging, let's quickly understand the history and origins of Kriging. Understanding the critical history of our tools has long been a tradition in Geography dating back to the 1960's. Notably, the role of Geographers in the construction of empire is a black mark on our field since it was first established in the 19th century, and evaluating how our current understanding of the field emerged from these violent frameworks shapes how we wield our knowledge to subvert those detestable origins. Precisely because you are learning quantitative Geographic or spatial statistical methods in the graduate program of Geography at UC Davis, you need to understand this. Critical cartography and critical Geography should not be dismissed simply because an elegant formula derived from a settler-colonial regime works well and advances our own projects. 

Danie Krige was born in Bothaville, South Africa in 1919. His obituary in the Canadian Mining Journal lauds him for his achievements and his contributions to advances in the field of resource extraction, not least of which for the Kriging technique. The Journal highlights his seminal paper in 1951; it illustrates how he rose to prominence in the Anglovaal mining corporation; and later how he retired from the private sector to become a respected professor at a South African university. However, the Journal at no point considers the man in the context of his times. Krige entered the industry and advanced it during a critical stage in the industrialization and development of South Africa. His seminal paper was published only three years after the enactment of Apartheid legislation in 1948. His role as a financial engineer emerges during this period and we should consider this timing in the creation and valorization of the Kriging technique. 

The mining industry has long been a pillar of the economy of South Africa. As professor of Geography at the University of Alabama Bobby Wilson describes, South Africa's political economy, like Birmingham Alabama, was founded on race-connected practices.

> "Owners of production used race-connected practices to regulate the struggle between themselves and workers and used racial (as well as gender and ethnic) divisions of labor to restructure production to make it more profitable." (B. Wilson 2000)

In other words, the wealth created by Krige's methods never went to the exploited Black miners in South Africa. The South African regime of using forced oscillating migrant labor to develop its white afluent cities depended on the suppressed wages of Black workers and the racial institutions and segregation that became codified by Apartheid legislation (F. Wilson 2001). Thus far, having describing this in political economic terms, I have not elaborated the day-to-day immiseration these systems enacted on the Black population of South Africa, but rest assured that the working conditions were deplorable. 

The point here is not to demonize the individual that developed the method of interpolation we use here in this lab. The problem is social and not individual. Rather, the point is that the development of Kriging is directly tied to racial-capitalism, to the exploitation of Black workers, and emerged out of an industry that benefitted from and contributed to the construction of Apartheid South Africa. Should this history not be recounted as we utilize these methods? What lessons does this leave us when using quantitative methods? Should not the memory of Danie Krige be complicated with the blood and sweat of forced labor? How did Kriging aid the Apartheid program? How will you use Kriging to subvert its origins in expanding the exploitive South African mining industry?

**References**

Obituary: Danie Krige, South Africa’s giant of geostatistics. 2013. Canadian Mining Journal. http://www.canadianminingjournal.com/news/obituary-danie-krige-south-africas-giant-of-geostatistics/ (last accessed 1 June 2020).

Wilson, B. M. 2000. America’s Johannesburg: industrialization and racial transformation in Birmingham. Lanham, Maryland: Rowman & Littlefield Publishers.

Wilson, F. 2001. Minerals and Migrants: How the Mining Industry Has Shaped South Africa. Daedalus 130 (1):99–121.

---

## Question 1

Do this first if you haven't already:

```{r eval=F}
r <- raster(TX)
res(r) <- 10
g <- as(r, 'SpatialGrid')
coordnames(g) <- c("X", "Y")
```

And make sure you created the function `RMSE`.


## Question 3

Fill in the relevant model specification (`formula`).

```{r eval=F}
# Quadratic Polynomial
quadratic_TX <- lm(formula = ENTER_MODEL_SPECIFICATION_HERE ~ 
                  X + 
                  Y + 
                  I(X*X) + 
                  I(Y*Y) + 
                  I(Y*X), 
                data=P)

# Use the regression model output to interpolate the surface
sgdf <- SpatialGridDataFrame(g, 
                             data.frame(var1.pred = 
                                          predict(quadratic_TX, newdata=g))) 

# Clip the interpolated raster to CA
r2   <- raster(sgdf)
r.m2 <- mask(r2, TX)

# Plot the map
tm_shape(r.m2) + 
  tm_raster(n=10, palette="RdBu", auto.palette.mapping=FALSE, 
            title="Predicted precip quadratic tsa") +
  tm_shape(P) + tm_dots(size=0.1) +
  tm_legend(legend.outside=TRUE)
```

```{r eval=F}
# Quadratic Cross Validation
set.seed(5132015)

kf <- kfold(nrow(P))

rmse_out <- rep(NA, 5)

for (k in 1:5) {
 
  test <- P[kf == k, ]
  train <- P[kf != k, ]
  
  quad_train <- lm(Precip_in ~ 
                     X + 
                     Y + 
                     I(X*X) + 
                     I(Y*Y) + 
                     I(Y*X), 
                   data = train)
  
  # save the predictions with the spatial grid g as a SpatialGridDataFrame
  sgdf <- SpatialGridDataFrame(g, 
                               data.frame(var1.pred = 
                                            predict(quad_train, 
                                                    newdata=g))) 
  
  # Clip the interpolated raster to TX
  r2   <- raster(sgdf)
  r.m2 <- mask(r2, TX)
  
  # Predict for test points.
  # note this p is different from the earlier P.
  p <- extract(r.m2, test)
  
  rmse_out[k] <- RMSE(test$Precip_in, 
                      p)
}

rmse_out

mean(rmse_out)

1 - (mean(rmse_out) / null)
```

## Question 4

**Create Variogram**

```{r eval=F}
plot(variogram(Precip_in~1, locations=P, width=200, cloud = TRUE))
```

You can play around with the cutoff and width. I found a width of 133 which looked nice such that a nugget was visible. You might play with a cutoff that ranges from say 800 to 3000. FYI, the average distance between points is 536km. You should try playing around with the cutoff and width.

```{r eval=F}
v.u <- variogram(Precip_in ~ Y + X, locations = P, cutoff = 2000)
plot(v.u)
```

Based off this plot what do you think the sill, range, and nugget are?

**Fit Variogram**

```{r eval=F}
# To quote LeVar Burton from Reading Rainbow
# "Don't take my word for it."
fve.u <- fit.variogram(v.u, model = vgm(psill = INSERT_YOUR_ESTIMATE_HERE, 
                                        model = INSERT_YOUR_ESTIMATE_HERE, 
                                        range = INSERT_YOUR_ESTIMATE_HERE, 
                                        nugget = INSERT_YOUR_ESTIMATE_HERE))
plot(v.u, fve.u)
```

```{r eval=F}
# krig
k.u <- gstat(formula = Precip_in~Y + X, locations = P, model=fve.u)

# predict
kp.u <- predict(k.u, g)
```

```{r eval=F}
# plot
# Convert kriged surface to a raster object for clipping
uk.u <- raster(kp.u)
uk.u <- mask(uk.u, TX)


tm_shape(uk.u) + 
  tm_raster(n=10, 
            palette="RdBu", 
            auto.palette.mapping=FALSE, 
            title="Precip in") +
  tm_legend(legend.outside=TRUE)
```

**CV**

```{r eval=F}
# Universal Kriging Cross Validation
set.seed(5132015)

kf <- kfold(nrow(P))

rmse_out <- rep(NA, 5)

for (k in 1:5) {
 
  test <- P[kf == k, ]
  train <- P[kf != k, ]
  
  gscv <- gstat(formula = Precip_in~Y + X, 
                locations = train, 
                model = fve.u)
  # predict
  p <- predict(gscv, 
               newdata = test, 
               debug.level = 0)$var1.pred
  rmse_out[k] <- RMSE(test$Precip_in, p)
}


rmse_out

mean(rmse_out)
```

# Regression Trees

## Question 1

Look at the baseball example starting on p 304 in ISLR for interpreting a regression tree graph. More specifically the last paragraph on p 305.

## Question 2

Generally, p314 in ISLR describes why we see terminal nodes that are both the same prediction. This isn't critical to understand in order to answer Question 2, but might help those of you scratching your heads.

To begin to answer this question, figure out the pathway it takes to get to all the "Yes" terminal nodes.

## Question 3

Try `help(tuneRF)`. Also try reading the first paragraph under "Random Forests" on p319, and the second to last paragraph on p320.