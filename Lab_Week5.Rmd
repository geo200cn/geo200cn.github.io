---
title: "Lab Lecture 5"
author: "Kenji Tomari"
output: 
  html_document:
    theme: readable
    toc: true
    toc_depth: 3
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=F}
library(tidyverse)
library(sf)
library(spdep)
library(tmap)
```

# Part 1

Below is a run through of Part 1 of Assignment 5.

```{r}
counties <- st_read("countiescovid.shp")
counties.sp <- as(counties, "Spatial")
```

```{r}
# Let's just look at California.
ca <- counties %>%
  filter(state == "California")

ca.sp <- ca %>%
  as("Spatial")
```

```{r}
# How many counties in CA?
nrow(ca)
```


```{r}
# quick map
ggplot() +
  geom_sf(data=ca, mapping = aes(fill = log(cases)), color = "red")
```

## Grab Coordinates

Before I begin the rest of the steps, I'll get the centroids.

```{r}
# get centroids of polygons
ca.coords <- coordinates(ca.sp)
```

## Queen Contiguity

Here we define the neighborhood using Queen Contiguity, and from this definition we assign weights to neighbors, and finally use Monte Carlo simulation to calculate the significance of our test of spatial autocorrelation (Moran's I).


```{r}
# create neighborhood matrix
# Note that strictly speaking, the R object is not matrix
ca_q_nb <- poly2nb(ca.sp, queen=T)
ca_q_nb
```

```{r}
# head
# take a look at the first 6 counties in the neighborhood matrix
ca_q_nb[1:6]
```


```{r}
# create spatial weights matrix
# Note that strictly speaking, the R object is not matrix
ca_q_w <- nb2listw(ca_q_nb, style="W", zero.policy= TRUE)
ca_q_w
```

Note, you may run across an error when running this code above. When I run `ca_q_w` by itself, its actually invoking the `print` function, but specified to work with the output of `nb2listw`. So, you need to tell it to ignore regions with no neighbors, just like you did in `nb2listw`. So instead, you could type `print(ca_q_w, zero.policy = TRUE)`.

```{r}
# quick look at the weights
ca_q_w$weights[1:6]
```


```{r}
# quick plot
plot(ca.sp, border = "grey60")
plot(ca_q_w, coords = ca.coords, add=T, col=2)
```

```{r}
# global moran's I using Monte Carlo
moran.mc(ca.sp$crate, ca_q_w, nsim=999, zero.policy= TRUE)
```

**Insert your interpretation here.**

## Distance, 50mi

50 miles is 80467.2 meters.

```{r}
ca_nb_dist50 <- dnearneigh(ca.coords, 
                           d1 = 0, 
                           d2 = 80467.2, 
                           row.names = ca.sp$county)

ca_nb_dist50_w <-nb2listw(ca_nb_dist50, style="W", zero.policy= TRUE)
```

Note, the `row.names` argument must be unique. So for the entire US, the `county` column is actually not unique. Try using `countyFIPS`.

```{r}
# global moran's I using Monte Carlo
moran.mc(ca.sp$crate, ca_nb_dist50_w, nsim=999, zero.policy= TRUE)
```

**Insert your interpretation here.**

## Distance, 100mi

100 mi is 160934.4 meters.

```{r}
ca_nb_dist100 <- dnearneigh(ca.coords, 
                           d1 = 0, 
                           d2 = 160934.4, 
                           row.names = ca.sp$county)

ca_nb_dist100_w <-nb2listw(ca_nb_dist50, style="W", zero.policy= TRUE)
```

```{r}
# global moran's I using Monte Carlo
moran.mc(ca.sp$crate, ca_nb_dist100_w, nsim=999, zero.policy= TRUE)
```

**Insert your interpretation here.**

## LISA

### Queen

```{r}
# lets get neighboods, ie spatial structure matrix, including selves
ca_q_nb.self <- include.self(ca_q_nb)
# create weights matrix
ca_q_nb.self_w <- nb2listw(ca_q_nb.self, style="W", zero.policy= TRUE)
# use G*
localgstar <- localG(ca.sp$crate, ca_q_nb.self_w, zero.policy = TRUE)
# Examine summary values
summary(localgstar)
```

**Insert your interpretation here.**

```{r}
# turn back into sf object for mapping
queen_sf <- mutate(ca, localgstar = as.numeric(localgstar))
```

```{r}
# map with quintile
tm_shape(queen_sf, unit = "mi") +
  tm_polygons(col = "localgstar", 
              title = "Gi* value",
              palette = "-RdBu", 
              style = "quantile") +
  tm_scale_bar(breaks = c(0, 10, 20), text.size = 1) +
  tm_layout(frame = F, main.title = "Queen Continguity",
            legend.outside = T) 
```


### Dist 50mi

```{r}
ca_nb_dist50.self <- include.self(ca_nb_dist50)
ca_nb_dist50.self_w <- nb2listw(ca_nb_dist50.self , style="W", zero.policy= TRUE)
localgstar <- localG(ca.sp$crate, ca_nb_dist50.self_w, zero.policy = TRUE)
summary(localgstar)
```

**Insert your interpretation here.**

```{r}
dist50_sf <- mutate(ca, localgstar = as.numeric(localgstar))
```

```{r}
# map with decile
tm_shape(dist50_sf, unit = "mi") +
  tm_polygons(col = "localgstar", 
              title = "Gi* value",
              palette = "-RdBu", 
              style = "quantile",
              n = 10) +
  tm_scale_bar(breaks = c(0, 10, 20), text.size = 1) +
  tm_layout(frame = F, main.title = "Distance 50 mi",
            legend.outside = T) 
```

### Dist 100mi

```{r}
ca_nb_dist100.self <- include.self(ca_nb_dist100)
ca_nb_dist100.self_w <- nb2listw(ca_nb_dist100.self , style="W", zero.policy= TRUE)
localgstar <- localG(ca.sp$crate, ca_nb_dist100.self_w, zero.policy = TRUE)
summary(localgstar)
```

**Insert your interpretation here.**

```{r}
dist100_sf <- mutate(ca, localgstar = as.numeric(localgstar))
```


```{r}
breaks <- c(-Inf, -2.58, -1.96, -1.65, 1.65, 1.96, 2.58, Inf)

# map with z-scores as break
tm_shape(dist100_sf, unit = "mi") +
  tm_polygons(col = "localgstar", title = "Gi* value", palette = "-RdBu",
              breaks = breaks) +
  tm_scale_bar(breaks = c(0, 10, 20), text.size = 1) +
  tm_layout(frame = F, main.title = "Distance 100 mi",
            legend.outside = T)
```

# Part II

## Question 1

Read BBR p 182-3 on residuals and p 174-7 beginning with "Estimation of a Linear Regression Function" for an introduction on fitting a line.

Also, these may be useful references as well from Statistics by Jim: [fitted values](https://statisticsbyjim.com/glossary/fitted-values/) and [residuals](https://statisticsbyjim.com/glossary/residuals/).

## Question 2

Again, BBR p174 should be useful in answering this question.

## Question 3

Use equation 4-4 and the values reported under "Coefficients" and "Estimate" when running `summary(lm1)`. 

## Question 4

The simplest way to do this in R would be to use two functions followed by each other in the same code chunk, `plot` and `lines`, like so:

```{r eval=F}
plot(your_response_variable ~ your_independent_variable, your_data_frame)
lines(your_data_frame$your_response_variable, 
      predict(your_lm_object), 
      col = "blue")
```

Replace all the arguments beginning with `your_` with the appropriate names.

## Question 5

Where does the *name* `poorPoor` actually come from? Well because the `poor` column in `zctanyc` is qualitative, the output for the `Poor` category in the column `poor` is given the prefix `poor`. You'll see in the next question, when running `lm` on the `borough` column, a similar naming scheme: "boroughBrooklyn", "boroughQueens", etc.

For more information on interpeting the "Coefficients" in the summary output of `lm`, check out this article on [Regression with Categorical Variables](http://www.sthda.com/english/articles/40-regression-analysis/163-regression-with-categorical-variables-dummy-coding-essentials-in-r/).

## Question 6

See Question 5.

## Question 7

The r^2 is described beginning on the bottom of p. 182 in BBR. This [article](https://statisticsbyjim.com/regression/interpret-r-squared-regression/) may be of use as well.

