<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Model Resampling and Selection</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/yeti.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 45px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h2 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h3 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h4 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h5 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h6 {
  padding-top: 50px;
  margin-top: -50px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">GEO 200CN: Winter 2020</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="syllabus.html">Syllabus</a>
</li>
<li>
  <a href="hw_guidelines.html">Assignment Guidelines</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Labs
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="getting_started.html">Getting Started</a>
    </li>
    <li>
      <a href="tidyr.html">Intro to tidyverse</a>
    </li>
    <li>
      <a href="central.html">Sampling, CIs, CLT</a>
    </li>
    <li>
      <a href="hypothesis.html">Hypothesis Testing</a>
    </li>
    <li>
      <a href="spatialsf.html">Mapping in sf</a>
    </li>
    <li>
      <a href="pointpatterns.html">Point Pattern Analysis</a>
    </li>
    <li>
      <a href="spatialautocorrelation.html">Spatial Autocorrelation</a>
    </li>
    <li>
      <a href="linearregression.html">Linear Regression I</a>
    </li>
    <li>
      <a href="linearregression2.html">Linear Regression II</a>
    </li>
    <li>
      <a href="spatialreg.html">Spatial Regression</a>
    </li>
    <li>
      <a href="spatialheterogeneity.html">Spatial Heterogeneity</a>
    </li>
    <li>
      <a href="classification.html">Classification</a>
    </li>
    <li>
      <a href="resampling.html">Resampling and Selection</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Lab Lectures
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Lab_Week1.html">Lab Lecture - 1</a>
    </li>
    <li>
      <a href="Lab_Week2.html">Lab Lecture - 2</a>
    </li>
    <li>
      <a href="Lab_Week3.html">Lab Lecture - 3</a>
    </li>
    <li>
      <a href="Lab_Week4.html">Lab Lecture - 4</a>
    </li>
    <li>
      <a href="Lab_Week5.html">Lab Lecture - 5</a>
    </li>
    <li>
      <a href="Lab_Week6.html">Lab Lecture - 6</a>
    </li>
    <li>
      <a href="Lab_Week7.html">Lab Lecture - 7</a>
    </li>
    <li>
      <a href="Lab_Week8.html">Lab Lecture - 8</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Other
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a></a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Model Resampling and Selection</h1>
<h3 class="subtitle"><h4 style="font-style:normal">
GEO 200CN - Quantitative Geography
</h4></h3>
<h4 class="author"><h4 style="font-style:normal">
Professor Noli Brazil
</h4></h4>
<h4 class="date"><h4 style="font-style:normal">
Spring 2020
</h4></h4>

</div>


<style>
p.comment {
background-color: #DBDBDB;
padding: 10px;
border: 1px solid black;
margin-left: 25px;
border-radius: 5px;
font-style: italic;
}

.figure {
   margin-top: 20px;
   margin-bottom: 20px;
}

h1.title {
  font-weight: bold;
  font-family: Arial;  
}

h2.title {
  font-family: Arial;  
}

</style>
<style type="text/css">
#TOC {
  font-size: 13px;
  font-family: Arial;
}
</style>
<p><br />
</p>
<p>In the last lab guide, we learned how to partition our data into training and testing sets to estimate the predictive quality of a regression model. In this lab, we extend this knowledge by going through the resampling techniques described in ISRL Ch. 5. We further expand our statistical toolkit by exploring methods that will allow us to choose the best set of predictors based on predictive quality. These methods are discussed in ISLR Ch 6. Although discussed in separate chapters, these methods are <a href="https://www.youtube.com/watch?v=FA5jsa1lR9c">intimately tied</a>. You run a Ch. 6 method to give a set of possible models and then you run a Ch. 5 method to give you a metric for determining which model gives the best predictive fit.</p>
<p>The objectives of this lab are as follows</p>
<ol style="list-style-type: decimal">
<li>Learn how to run cross validation to calculate test error rates</li>
<li>Learn how to run forward and backward stepwise selection</li>
<li>Learn how to run ridge and lasso regression</li>
<li>Learn how to select from models in (2) and (3) using the methods learned in (1)</li>
</ol>
<p>To help us accomplish objective 1, we will use temperature data for California weather stations. To help us accomplish objectives 2-4, we will use a data set from the previous lab - 2017 <a href="https://www.cdc.gov/brfss/index.html">Behavioral Risk Factor Surveillance System</a> (BRFSS). Download the data for this lab guide from Canvas in the Labs and Assignments Week 8 folder. All the data are zipped into the file <em>resampling.zip</em>.</p>
<div style="margin-bottom:25px;">

</div>
<div id="installing-and-loading-packages" class="section level2">
<h2><strong>Installing and loading packages</strong></h2>
<p><br />
We’ll be using several new packages in this lab. First, install them if you haven’t already.</p>
<pre class="r"><code>if (!require(&quot;dismo&quot;)) install.packages(&quot;dismo&quot;)
if (!require(&quot;leaps&quot;)) install.packages(&quot;leaps&quot;)
if (!require(&quot;glmnet&quot;)) install.packages(&quot;glmnet&quot;)</code></pre>
<p>Second, load all necessary packages.</p>
<pre class="r"><code>library(sf)
library(broom)
library(dismo)
library(leaps)
library(glmnet)
library(tidyverse)</code></pre>
<div style="margin-bottom:25px;">

</div>
</div>
<div id="california-temperature-data" class="section level2">
<h2><strong>California Temperature Data</strong></h2>
<p><br />
To demonstrate cross validation, we’ll be relying on a dataset containing monthly temperature data for weather stations in California. Bring in the dataset <em>temperature.csv</em></p>
<pre class="r"><code>ca.temp &lt;- read_csv(&quot;temperature.csv&quot;)</code></pre>
<p>The file contains the average monthly temperature in Celsius. Let’s take mean monthly temperature, which will be our response variable.</p>
<pre class="r"><code>ca.temp &lt;- mutate(ca.temp, temp = rowMeans(dplyr::select(ca.temp, JAN:DEC)))</code></pre>
<p>Let’s map the stations. We have longitude and latitude. First, we need to convert <em>ca.temp</em> into a spatial <strong>sf</strong> object. Here, we use the function <code>st_as_sf()</code> and use an appropriate coordinate reference system.</p>
<pre class="r"><code>ca.temp.sf &lt;- st_as_sf(ca.temp, coords = c(&quot;LONG&quot;, &quot;LAT&quot;), crs =&quot;+proj=longlat +datum=NAD83 +ellps=GRS80&quot;)</code></pre>
<p>Let’s then bring in a California counties layer.</p>
<pre class="r"><code>cacounties &lt;- st_read(&quot;counties_2000.shp&quot;)</code></pre>
<p>Next, we need to transform both layers to a planar CRS (Teale Albers in this case) to assure that the computations we perform later are OK. That is, we want to avoid interpreting angles as if they were planar coordinates.</p>
<pre class="r"><code>st_crs(ca.temp.sf)</code></pre>
<pre><code>## Coordinate Reference System:
##   EPSG: 4269 
##   proj4string: &quot;+proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs&quot;</code></pre>
<pre class="r"><code>st_crs(cacounties)</code></pre>
<pre><code>## Coordinate Reference System:
##   EPSG: 4269 
##   proj4string: &quot;+proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs&quot;</code></pre>
<pre class="r"><code>TA &lt;- crs(&quot; +proj=aea +lat_1=34 +lat_2=40.5 +lat_0=0 +lon_0=-120 +x_0=0
+y_0=-4000000 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0&quot;)

ca.temp.sf&lt;- st_transform(ca.temp.sf, TA)
cacounties&lt;- st_transform(cacounties, TA)

st_crs(ca.temp.sf)</code></pre>
<pre><code>## Coordinate Reference System:
##   No EPSG code
##   proj4string: &quot;+proj=aea +lat_1=34 +lat_2=40.5 +lat_0=0 +lon_0=-120 +x_0=0 +y_0=-4000000 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs&quot;</code></pre>
<p>Finally, mapification happens.</p>
<pre class="r"><code>ggplot(data = cacounties) +geom_sf() +
          geom_sf(data = ca.temp.sf, aes(color = temp)) +
      scale_color_gradient(low = &quot;blue&quot;, high = &quot;red&quot;, name =&quot;Temperature&quot;) + 
    theme( axis.text =  element_blank(),
    axis.ticks =  element_blank(),
    panel.background = element_blank())</code></pre>
<p><img src="resampling_files/figure-html/unnamed-chunk-8-1.png" /><!-- --></p>
<p>Now on to the modelling!!</p>
<div style="margin-bottom:25px;">

</div>
</div>
<div id="prediction-model" class="section level2">
<h2><strong>Prediction model</strong></h2>
<p><br />
The goal is to create a model that predicts temperature. We first run a linear regression model with no independent variables (known as a null model). Such a model uses the mean annual temperature across the stations as an estimator of temperature at every location.</p>
<pre class="r"><code>null &lt;- lm(temp ~ 1, data = ca.temp.sf)</code></pre>
<p>Save the predicted values (which is just the mean) and the residuals (observed - predicted) into our data frame. The function <code>predict()</code> gives us the predicted values and the function <code>resid()</code> gives us the residuals.</p>
<pre class="r"><code>ca.temp.sf &lt;- mutate(ca.temp.sf, nullpred = predict(null), nullresid = resid(null))</code></pre>
<p>And we make a map of the residuals.</p>
<pre class="r"><code>ggplot(data = cacounties) +geom_sf() +
          geom_sf(data = ca.temp.sf, aes(color = nullresid)) +
    scale_color_gradient(low = &quot;blue&quot;, high = &quot;red&quot;, name =&quot;Residual&quot;) + 
    theme( axis.text =  element_blank(),
    axis.ticks =  element_blank(),
    panel.background = element_blank())</code></pre>
<p><img src="resampling_files/figure-html/unnamed-chunk-11-1.png" /><!-- --></p>
<p>This does not look very good. There are large differences. Moreover, there is some spatial autocorrelation in the residuals, indicating that some places have better predictions than others.</p>
<p>Because we are now in prediction land, we are very concerned about fit. A very important measure of fit is the Root Mean Squared Error (RMSE). Let’s define an RMSE function so we can compute RMSE for all the models we run in this lab.</p>
<pre class="r"><code>RMSE &lt;- function(observed, predicted) {
          sqrt(mean((predicted - observed)^2, na.rm=TRUE))
}</code></pre>
<p>Next, we calculate the RMSE of the null model.</p>
<pre class="r"><code>RMSE(ca.temp.sf$temp, ca.temp.sf$nullpred)</code></pre>
<pre><code>## [1] 3.722373</code></pre>
<div style="margin-bottom:25px;">

</div>
</div>
<div id="cross-validation" class="section level2">
<h2><strong>Cross-Validation</strong></h2>
<p><br />
We can probably do better than use the mean to predict temperature. Let’s try a linear regression model with independent variables. The only meaningful attribute we have in our <em>ca.temp.sf</em> dataset is the geographic coordinates, i.e. the location of each weather station. A regression of any variable on geographic coordinates is known as a trend surface model, which we’ll cover in more detail next week (Ch. 9 in OSU). But, for now, let’s regress temperature on a station’s longitude and latitude. Let’s also compute an error rate using k-cross validation, which is described in section 5.1.3 in ISLR.</p>
<p>We first need to cut up the data set into <em>k</em> sets. Let’s set <em>k</em> = 10. We can use the function <code>kfold()</code>, which is a part of the <strong>dismo</strong> package, to conveniently partition our data into <em>k</em> folds. For replication purposes, I <code>set.seed()</code> because <code>kfold()</code> randomly partitions the data set.</p>
<pre class="r"><code>set.seed(5162016)
k &lt;- kfold(ca.temp.sf, k = 10)
table(k)</code></pre>
<pre><code>## k
##  1  2  3  4  5  6  7  8  9 10 
## 30 30 31 30 30 30 30 31 30 30</code></pre>
<p>The output shows that 30 observations are in the test set of the first fold, 30 different observations are in the second fold, 31 different observations are in the third fold, and so on. Let’s visualize what we have done for one fold:</p>
<pre class="r"><code>test &lt;- ca.temp.sf[k==1, ]
train &lt;- ca.temp.sf[k!=1, ]

ggplot(data = cacounties) +geom_sf() +
          geom_sf(data = train, aes(color = &quot;blue&quot;), show.legend = &quot;point&quot;) +
          geom_sf(data = test, aes(color = &quot;red&quot;), show.legend = &quot;point&quot;)  +
    scale_color_manual(labels = c(&quot;model training&quot;, &quot;model testing&quot;), values = c(&quot;blue&quot;, &quot;red&quot;), name = &quot;&quot;) +
    theme( axis.text =  element_blank(),
    axis.ticks =  element_blank(),
    panel.background = element_blank())</code></pre>
<p><img src="resampling_files/figure-html/unnamed-chunk-15-1.png" /><!-- --></p>
<p>Let’s run a linear regression on our first fold. First, save the coordinates and temperature into a single data frame.</p>
<pre class="r"><code>df &lt;- data.frame(st_coordinates(train), temp=train$temp)</code></pre>
<p>Then fit a linear regression model to these data. We’ll use <code>glm()</code>.</p>
<pre class="r"><code>m &lt;- glm(temp ~ X+Y, data=df)
summary(m)</code></pre>
<pre><code>## 
## Call:
## glm(formula = temp ~ X + Y, data = df)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -9.4411  -1.5265   0.1872   1.7846   8.9485  
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  1.390e+01  1.984e-01  70.055  &lt; 2e-16 ***
## X            5.125e-07  1.428e-06   0.359     0.72    
## Y           -8.464e-06  1.025e-06  -8.257  6.8e-15 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 7.891022)
## 
##     Null deviance: 3803.0  on 271  degrees of freedom
## Residual deviance: 2122.7  on 269  degrees of freedom
## AIC: 1338.8
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<p><br></p>
<p class="comment" , style="font-style:normal">
<strong>Question 1</strong>: According to this model. How much does the temperature in California change if you travel 500 miles to the north?
</p>
<p><br></p>
<p>We can now estimate temperature values for our hold-out (test) sample</p>
<pre class="r"><code>v &lt;- data.frame(st_coordinates(test))
p &lt;- predict(m, v)
#First several predictions
head(p)</code></pre>
<pre><code>##        1        2        3        4        5        6 
## 18.49892 17.27353 17.99420 16.04129 13.71275 12.06281</code></pre>
<p>And then evaluate the results by comparing them with the known values for these locations using the <code>RMSE()</code> function we created above</p>
<pre class="r"><code>RMSE(p, test$temp)</code></pre>
<pre><code>## [1] 3.289749</code></pre>
<p>This looks better than the RMSE for the null (because it is smaller). But, we have to do this for all 10 folds. We can accomplish this by running a forgotten friend the for loop.</p>
<pre class="r"><code>r &lt;- rep(NA,5)
for (i in 1:10) {
  test &lt;- ca.temp.sf[k==i, ]
  train &lt;- ca.temp.sf[k!=i, ]
  df &lt;- data.frame(st_coordinates(train), temp=train$temp)
  m &lt;- glm(temp ~ ., data=df)
  v &lt;- data.frame(st_coordinates(test))
  p &lt;- predict(m, v)
  r[i] &lt;- RMSE(p, test$temp)
}</code></pre>
<p>The result is the RMSE for each of the 10 folds.</p>
<pre class="r"><code>r</code></pre>
<pre><code>##  [1] 3.289749 2.248640 3.043732 3.422114 2.533438 2.819896 2.794843 2.838339
##  [9] 3.011162 2.470722</code></pre>
<p>We then calculate the average, which is equation 5.3 shown on ISLR page 181 (we show the RMSE, ISLR shows the MSE, the only difference being MSE is squared).</p>
<pre class="r"><code>mean(r)</code></pre>
<pre><code>## [1] 2.847263</code></pre>
<p>The model is not great, but it did capture something, and it is better than the null model.</p>
<p>We did the <em>k</em>-fold cross-validation technique described in ISLR 5.1.3. Now do the leave-one-out cross-validation technique described in 5.1.2 and 5.3.2. You can use the function <code>cv.glm()</code>, which is a part of the <strong>boot</strong> package. See page 192 in ISLR for a demonstration of this function. You don’t need to separate the data set into training and test data sets as <code>cv.glm()</code> will automatically do that for you. So, you can save the coordinates and the temperature for the entire set of locations in a data frame</p>
<pre class="r"><code>df2 &lt;- data.frame(st_coordinates(ca.temp.sf), temp = ca.temp.sf$temp)</code></pre>
<p>and go from there</p>
<p><br></p>
<p class="comment" , style="font-style:normal">
<strong>Question 2</strong>: What is the RMSE using leave-one-out cross validation?
</p>
<p><br></p>
<div style="margin-bottom:25px;">

</div>
</div>
<div id="subset-selection" class="section level2">
<h2><strong>Subset Selection</strong></h2>
<p><br />
The California temperature data is not that interesting when trying to show how to run subset selection techniques in R because we don’t have any attributes outside of the stations’ geographic coordinates. Subset selection is best illustrated using a model with many potential covariates. As such, let’s turn back to a data set we ended in our prior lab, 2017 BRFSS data on individual health. Bring the data in.</p>
<pre class="r"><code>brfss17 &lt;- read_csv(&quot;brfss17.csv&quot;)</code></pre>
<p>Here, we’ll predict the numeric variable <em>physhlth</em>, which gives the number of days in the past month that respondents felt that they were not in good physical health. Our independent variables are age <em>agec</em>, gender <em>male</em>, educational attainment <em>educ</em>, race/ethnicity <em>race_eth</em>, whether the individual indicates they <em>smoke</em>, employment status <em>employ</em>, marital status <em>marst</em>, BMI <em>bmi</em>, health insurance <em>ins</em>, income <em>inc</em>, and indicators of whether the individual has high blood pressure <em>bphigh</em>, high cholesterol <em>toldhi</em>, and was ever diagnosed with a heart attack <em>cvdinfr</em>, a Stroke <em>cvdstrk</em>, Asthma <em>asthma</em>, Arthritis <em>havarth</em>, or Diabetes <em>diabete</em>. A record layout of the data can be found <a href="https://raw.githubusercontent.com/geo200cn/data/master/brfss17RL.txt">here</a>. The goal is to find the best set of predictors for <em>physhlth</em> based on predictive quality.</p>
<div style="margin-bottom:25px;">

</div>
<div id="forward-and-backward-stepwise-selection" class="section level3">
<h3><strong>Forward and Backward Stepwise Selection</strong></h3>
<p><br />
The purpose of forward and backward stepwise selection is to iteratively fit a regression model by adding predictors one-by-one to a model with no variables (known as a null model) or subtracting predictors one-by-one from a full model (all predictors are included). The goal is to find the best combination of predictors, where best is based on some measure of predictive quality.</p>
<p>We can use the <code>regsubsets()</code> function, which is a part of the <strong>leaps</strong> package, to perform the best subset selection methods described in ISLR Ch 6.1. Let’s first run a forward stepwise selection (ISLR 6.1.2) to find the best predictors for poor physical health days. The syntax is the same as <code>lm()</code>, but we add the argument <code>method = &quot;forward&quot;</code></p>
<pre class="r"><code>regfit1.fwd &lt;- regsubsets(physhlth ~ bmi + race_eth + agec + male + smoke + educ + inc + employ + marst + ins + bphigh + toldhi + cvdinfr + cvdstrk + asthma + havarth + diabete, data = brfss17, method = &quot;forward&quot;)</code></pre>
<p>A summary of results.</p>
<pre class="r"><code>summary(regfit1.fwd)</code></pre>
<p>The <code>regsubsets()</code> function identifies the best model that contains a given number of predictors, where <em>best</em> is quantified as the lowest residual sum of squares (RSS). An asterisk indicates that a given variable is included in the corresponding best model. For example, the summary output indicates that the best two-variable model contains <em>employunable</em> and <em>havarth</em>. When interpreting these results, remember that categorical/qualitative variables are separated into dummy variables. Therefore, the variables <em>employnilf</em>, <em>employretired</em> and <em>employunable</em> correspond to separate dummies for the categories “not in labor force”, “retired”, and “unable to work” (the category “Employed” is the reference) in the <em>employ</em> variable. You can extract the coefficients and their values for the best 2-variable model by using the <code>coef()</code> function as follows</p>
<pre class="r"><code>coef(regfit1.fwd, 2)</code></pre>
<pre><code>##  (Intercept) employunable      havarth 
##     2.141179    11.496099     3.955133</code></pre>
<p>By default, the function only reports results up to the best eight-variable model, but you can use the <code>nvmax</code> option to return as many variables as desired. For example, let’s try a 33 variable model, with 33 representing the max number of predictors we can include for our case</p>
<pre class="r"><code>regfit2.fwd &lt;- regsubsets(physhlth ~ bmi + race_eth + agec + male + smoke + educ + inc + employ + marst + ins + bphigh + toldhi + cvdinfr + cvdstrk + asthma + havarth + diabete, data = brfss17, method = &quot;forward&quot;, nvmax = 33)</code></pre>
<p>After getting the best model for each given number of predictors, we need to then select the best model across all sets. Following ISLR, we can examine the adjusted <span class="math inline"><em>R</em><sup>2</sup></span>, <span class="math inline"><em>C</em><em>p</em></span> and the Bayesian Information Criterion (BIC) from the <code>summary()</code> output. Let’s examine the adjusted <span class="math inline"><em>R</em><sup>2</sup></span>, which is discussed on page 212 in ISLR.</p>
<pre class="r"><code>regfit2.fwd.summary &lt;- summary(regfit2.fwd)
regfit2.fwd.summary$adjr2</code></pre>
<pre><code>##  [1] 0.1277702 0.1732549 0.1872198 0.1944227 0.1997421 0.2040115 0.2068957
##  [8] 0.2081920 0.2093504 0.2105600 0.2117409 0.2125584 0.2132344 0.2138314
## [15] 0.2143430 0.2146413 0.2148545 0.2150567 0.2151948 0.2152931 0.2153752
## [22] 0.2154121 0.2154404 0.2154770 0.2155044 0.2155138 0.2155498 0.2155559
## [29] 0.2155538 0.2155509 0.2155471 0.2155545 0.2155499</code></pre>
<p>We see that the adjusted <span class="math inline"><em>R</em><sup>2</sup></span> increases from 12.8 with one variable to 21.6 with all variables.</p>
<p>We can look at all fit indicators to decide which model is the best. Plotting adjusted <span class="math inline"><em>R</em><sup>2</sup></span>, <span class="math inline"><em>C</em><em>p</em></span>, and BIC for all of the models at once can help us decide which model to select. Note the <code>type=&quot;l&quot;</code> option tells R to connect the plotted points with lines.</p>
<pre class="r"><code>par(mfrow = c(2,2))
plot(regfit2.fwd.summary$adjr2 , xlab =&quot; Number of Variables &quot;, ylab =&quot; Adjusted RSq &quot;, type =&quot;l&quot;)
plot(regfit2.fwd.summary$cp, xlab =&quot; Number of Variables &quot;, ylab =&quot;Cp&quot;, type =&#39;l&#39;)
plot(regfit2.fwd.summary$bic ,xlab =&quot; Number of Variables &quot;,ylab =&quot; BIC &quot;, type =&#39;l&#39;)</code></pre>
<p><img src="resampling_files/figure-html/unnamed-chunk-30-1.png" /><!-- --></p>
<p><br></p>
<p class="comment" , style="font-style:normal">
<strong>Question 3</strong>: Which model does the adjusted <span class="math inline"><em>R</em><sup>2</sup></span> indicate is the best? In your answer, identify the specific variables that are included in the best model.
</p>
<p class="comment" , style="font-style:normal">
<strong>Question 4</strong>: Run backwards stepwise regression. Which model is identified as the best model based on adjusted <span class="math inline"><em>R</em><sup>2</sup></span>? In your answer, identify the specific variables that are included in the best model.
</p>
<p><br></p>
<div style="margin-bottom:25px;">

</div>
</div>
<div id="cross-validation-error" class="section level3">
<h3><strong>Cross-validation error</strong></h3>
<p><br />
We just saw that it is possible to choose among a set of models of different sizes using BIC, adjusted <span class="math inline"><em>R</em><sup>2</sup></span> and other best fit metrics. We will now consider how to do this within a cross-validation framework. Here, you will use cross-validation to find the best model with the lowest validation error. This will combine the methods from ISLR Chapter 5 and Chapter 6, which is described on page 213 in ISLR.</p>
<p>We will choose among the best models of different sizes using cross validation. This approach is somewhat involved, as we must perform subset selection within each of the <em>k</em> training sets. Despite this, subsetting in R makes this job quite easy. First, we create a vector that allocates each observation to one of <em>k</em> = 10 folds using the fabulous function <code>kfold()</code></p>
<pre class="r"><code>set.seed(1234)
brfss17 &lt;- mutate(brfss17, folds = kfold(brfss17, k = 10))
table(brfss17$folds)</code></pre>
<pre><code>## 
##     1     2     3     4     5     6     7     8     9    10 
## 15811 15810 15811 15811 15811 15810 15811 15811 15810 15811</code></pre>
<p>and we create a matrix in which we will store the results. Rows represent the k = 10 folds and columns represent the complete set of variables (33) we are including in the model.</p>
<pre class="r"><code>k=10
cv.errors = matrix(NA ,k,33, dimnames =list(NULL , paste (1:33) ))</code></pre>
<p>Now we write a for loop that performs cross-validation. The loop is similar to the one we used to do cross-validation on California temperature. In the <span class="math inline"><em>j</em></span>th fold, the elements of folds that equal <em>j</em> are in the test (or validation) set, and the remainder are in the training set. We make our predictions for each model size, compute the test errors on the appropriate subset, and store them in the appropriate slot in the matrix <em>cv.errors</em>.</p>
<p>There is a complication: there is no <code>predict()</code> method for <code>regsubsets()</code> like there is for <code>glm()</code> or <code>lm()</code>. Fortunately, ISLR created a predict function for us to use for <code>regsubsets()</code> objects. I copy and paste their code below. If you would like to learn how this function was created, see ISLR 6.5.3.</p>
<pre class="r"><code>predict.regsubsets = function(object ,newdata ,id ,...) {
 form =as.formula(object$call[[2]])
 mat = model.matrix(form, newdata )
 coefi =coef(object ,id=id)
 xvars = names(coefi)
 mat [, xvars ]%*%coefi
}</code></pre>
<p>Now the for loop.</p>
<pre class="r"><code>for (j in 1:k){
  best.fit = regsubsets(physhlth ~ bmi + race_eth + agec + male + smoke + educ + inc + employ + marst + ins + bphigh + toldhi + cvdinfr + cvdstrk + asthma + havarth + diabete,
                        data = filter(brfss17, folds != j), method = &quot;forward&quot;, nvmax = 33)
  for (i in 1:33) {
    pred= predict(best.fit , filter(brfss17, folds == j), id=i)
    pred2 &lt;- (dplyr::select(filter(brfss17, folds == j), physhlth) - pred)^2
    cv.errors[j,i]= mean(pred2$physhlth)
    }
}</code></pre>
<p>This has given us a 10×33 matrix, of which the <em>(i, j)</em>th element corresponds to the test MSE for the ith cross-validation fold for the best <em>j</em>-variable model. We use the <code>apply()</code> function to average over the columns of this matrix in order to obtain a vector for which the <em>j</em>th element is the cross-validation error for the <em>j</em>-variable model</p>
<pre class="r"><code>mean.cv.errors =apply(cv.errors ,2, mean)
mean.cv.errors</code></pre>
<pre><code>##        1        2        3        4        5        6        7        8 
## 63.17279 59.87841 58.86750 58.34605 57.96128 57.65206 57.44342 57.37276 
##        9       10       11       12       13       14       15       16 
## 57.29870 57.19102 57.12315 57.04165 56.98713 56.95636 56.90768 56.88672 
##       17       18       19       20       21       22       23       24 
## 56.87541 56.86083 56.84728 56.84648 56.83535 56.84263 56.84084 56.83513 
##       25       26       27       28       29       30       31       32 
## 56.83088 56.83287 56.82971 56.82791 56.82835 56.82959 56.83118 56.83100 
##       33 
## 56.83043</code></pre>
<p>The model with the lowest error rate is</p>
<pre class="r"><code>min(mean.cv.errors)</code></pre>
<pre><code>## [1] 56.82791</code></pre>
<p>which corresponds to the 28-variable model. Let’s plot to visualize</p>
<pre class="r"><code>par(mfrow =c(1 ,1))
plot( mean.cv.errors , type=&#39;b&#39;)</code></pre>
<p><img src="resampling_files/figure-html/unnamed-chunk-37-1.png" /><!-- --></p>
<p><br></p>
<p class="comment" , style="font-style:normal">
<strong>Question 5</strong>: What are the variables and their coefficient values associated with the 28-variable model?
</p>
<p><br></p>
<div style="margin-bottom:25px;">

</div>
</div>
</div>
<div id="shrinkage-methods" class="section level2">
<h2><strong>Shrinkage Methods</strong></h2>
<p><br />
Shrinkage? <a href="https://www.youtube.com/watch?v=GG2dF5PS0bI">Like laundry?</a> Not quite.</p>
<p>The basis behind shrinkage methods is to, well, shrink the coefficients towards 0. Why would shrunk coefficients be better? This introduces bias, but may significantly decrease the variance of the estimates. If the latter effect is larger, this would decrease the test error. The driving force behind variable selection: the need for greater accuracy in prediction. In a prediction context, there is less concern about the values of the components on the right-hand side, rather interest is on the total contribution. We’ll cover two shrinkage methods: ridge and lasso regression. If you want to dig deep into the math, check ISLR Ch. 6.2. Otherwise, follow the conceptual pathway rather than getting too deep (or lost) in the weeds.</p>
<div style="margin-bottom:25px;">

</div>
<div id="ridge-and-lasso-regression" class="section level3">
<h3><strong>Ridge and Lasso Regression</strong></h3>
<p><br />
We can fit ridge and lasso regression models using the function <code>glmnet()</code> which is a part of the <strong>glmnet</strong> package. This function has slightly different syntax from other model-fitting functions that we have encountered thus far in this class (e.g. <code>lm()</code>, <code>glm()</code>, <code>lagsarlm()</code>). In particular, we must pass in a matrix <em>x</em> of independent variables rather than a data frame as well as a <em>y</em> vector.</p>
<p>The <code>model.matrix()</code> function is particularly useful for creating <em>x</em>; not only does it produce a matrix corresponding to the 33 predictors but it also automatically transforms any qualitative variables into dummy variables. The latter property is important because <code>glmnet()</code> can only take numerical, quantitative inputs. Create <em>x</em> using <code>model.matrix()</code> and set <em>y</em> as the response variable <em>brfss17$physhlth</em>.</p>
<pre class="r"><code>x &lt;- model.matrix(physhlth ~., dplyr::select(brfss17, physhlth, bmi, race_eth, agec, male, smoke , educ, inc, employ, marst, ins, bphigh, toldhi, cvdinfr, cvdstrk, asthma, havarth, diabete))[, -1]
y &lt;- brfss17$physhlth</code></pre>
<p>We’ve got our pieces to plug into <code>glmnet()</code>. The function has an alpha argument that determines what type of model is fit. If <code>alpha=0</code> then a ridge regression model is fit, and if <code>alpha=1</code> then a lasso model is fit. We also need to specify the argument <code>lambda</code>.</p>
<pre class="r"><code>grid &lt;-10^seq(10,-2, length =100)
regfit.ridge = glmnet(x,y,alpha =0, lambda =grid )</code></pre>
<p>Recall from ISLR 6.2.3, lambda is our key tuning parameter. By default the <code>glmnet()</code> function performs ridge regression for an automatically selected range of <code>lambda</code> values. However, here we have chosen to implement the function over a grid of 100 values ranging from <code>lambda</code> = <span class="math inline">10<sup>10</sup></span> to <code>lambda</code> = <span class="math inline">10<sup>−2</sup></span>. As we will see, we can also compute model fits for a particular value of lambda that is not one of the original grid values. Note that by default, the <code>glmnet()</code> function standardizes the variables so that they are on the same scale. To turn off this default setting, use the argument <code>standardize = FALSE</code>.</p>
<p>Associated with each value of lambda is a vector of ridge regression coefficients, stored in a matrix that can be accessed by <code>coef()</code>. In this case, it is a 34×100 matrix, with 34 rows (one for each predictor, plus an intercept) and 100 columns (one for each value of lambda).</p>
<pre class="r"><code>dim(coef(regfit.ridge))</code></pre>
<pre><code>## [1]  34 100</code></pre>
<p>We expect the coefficient estimates to be much smaller when a large value of lambda is used, as compared to when a small value of lambda is used. These are the coefficients when lambda = 11498</p>
<pre class="r"><code>regfit.ridge$lambda[50]</code></pre>
<pre><code>## [1] 11497.57</code></pre>
<pre class="r"><code>coef(regfit.ridge)[,50]</code></pre>
<pre><code>##          (Intercept)                  bmi     race_ethnh black 
##         4.084313e+00         1.268837e-04         2.626554e-04 
## race_ethnh multirace     race_ethnh other      race_ethnhwhite 
##         1.066839e-03        -3.761764e-04        -2.111790e-04 
##          agec(24,39]          agec(39,59]          agec(59,79] 
##        -1.408315e-03        -4.585996e-06         8.351994e-04 
##          agec(79,99]             maleMale          smokeFormer 
##         1.053666e-03        -6.639874e-04         6.756729e-04 
##     smokeNeverSmoked          educ1somehs          educ2hsgrad 
##        -1.428837e-03         2.575934e-03         9.878735e-04 
##         educ3somecol         educ4colgrad                  inc 
##         5.819408e-04        -1.629427e-03        -1.103627e-03 
##           employnilf        employretired         employunable 
##         3.085549e-04         7.601816e-04         9.529839e-03 
##        marstdivorced         marstmarried              marstnm 
##         1.411200e-03        -1.160753e-03        -3.079830e-04 
##       marstseparated         marstwidowed                  ins 
##         2.114507e-03         1.287844e-03        -2.362022e-05 
##               bphigh               toldhi              cvdinfr 
##         2.071257e-03         1.553035e-03         4.122153e-03 
##              cvdstrk               asthma              havarth 
##         4.690407e-03         2.345151e-03         3.689490e-03 
##              diabete 
##         3.111607e-03</code></pre>
<p>In contrast, here are the coefficients when lambda = 705.</p>
<pre class="r"><code>regfit.ridge$lambda[60]</code></pre>
<pre><code>## [1] 705.4802</code></pre>
<pre class="r"><code>coef(regfit.ridge)[,60]</code></pre>
<pre><code>##          (Intercept)                  bmi     race_ethnh black 
##         4.0504905434         0.0020005999         0.0037397803 
## race_ethnh multirace     race_ethnh other      race_ethnhwhite 
##         0.0169757526        -0.0057351102        -0.0031814796 
##          agec(24,39]          agec(39,59]          agec(59,79] 
##        -0.0218565403         0.0002131867         0.0128217695 
##          agec(79,99]             maleMale          smokeFormer 
##         0.0162648940        -0.0105069817         0.0103408837 
##     smokeNeverSmoked          educ1somehs          educ2hsgrad 
##        -0.0224062522         0.0404244624         0.0153098275 
##         educ3somecol         educ4colgrad                  inc 
##         0.0090557469        -0.0254009094        -0.0174243586 
##           employnilf        employretired         employunable 
##         0.0051264463         0.0116170232         0.1521595719 
##        marstdivorced         marstmarried              marstnm 
##         0.0220844534        -0.0180530037        -0.0048032994 
##       marstseparated         marstwidowed                  ins 
##         0.0333203184         0.0197562125        -0.0003278925 
##               bphigh               toldhi              cvdinfr 
##         0.0324397431         0.0243132571         0.0651214899 
##              cvdstrk               asthma              havarth 
##         0.0741552994         0.0373256610         0.0585609896 
##              diabete 
##         0.0490685846</code></pre>
<p>OK, so which lambda do we go with? In general, instead of arbitrarily choosing a lambda, it would be better to use our new best pal cross-validation to choose the value of this tuning parameter. This is described on page 227 in ISLR. We can do this using the built-in cross-validation function, <code>cv.glmnet()</code>. By default, the function <code>cv.glmnet()</code> performs ten-fold cross-validation, though this can be changed using the argument <code>folds</code>. Note that we set a random seed first so our results will be reproducible, because the choice of the cross-validation folds is random.</p>
<pre class="r"><code>set.seed(1234)
cv.out =cv.glmnet(x,y, alpha =0, lambda = grid)
bestlam =cv.out$lambda.min
bestlam</code></pre>
<pre><code>## [1] 0.03053856</code></pre>
<p>We see that the value of lambda that results in the smallest cross-validation error is 0.03053856.</p>
<p>We’ve got our best lambda, now we fit the ridge regression.</p>
<pre class="r"><code>out &lt;- glmnet(x,y,alpha =0, lambda = bestlam)</code></pre>
<p>The ridge regression coefficients for our new value of lambda is</p>
<pre class="r"><code>coef(out)</code></pre>
<pre><code>## 34 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                                s0
## (Intercept)           2.830499147
## bmi                   0.047532909
## race_ethnh black     -0.755931016
## race_ethnh multirace  0.594441633
## race_ethnh other      0.089154005
## race_ethnhwhite       0.198880924
## agec(24,39]           0.446930184
## agec(39,59]           0.535009679
## agec(59,79]          -0.146020858
## agec(79,99]           0.074366529
## maleMale             -0.256979833
## smokeFormer          -0.581880096
## smokeNeverSmoked     -0.948514406
## educ1somehs           0.002260339
## educ2hsgrad          -0.180086678
## educ3somecol         -0.003100523
## educ4colgrad         -0.202204595
## inc                  -0.533779319
## employnilf            1.265765977
## employretired         1.010321146
## employunable          9.768290932
## marstdivorced         0.031915815
## marstmarried         -0.269647318
## marstnm              -0.322224688
## marstseparated        0.339368048
## marstwidowed         -0.494083775
## ins                   0.065772033
## bphigh                0.522395761
## toldhi                0.298632337
## cvdinfr               2.226214922
## cvdstrk               2.276251323
## asthma                1.499765561
## havarth               2.918022579
## diabete               1.488135575</code></pre>
<p>Unlike stepwise regression, which controls the complexity of the model by restricting the number of predictors, ridge regression keeps all of the predictor variables in the model, and shrinks the coefficients toward zero.</p>
<p>The above procedure uses cross-validation to decide which lambda to choose. But what if you wanted to decide whether ridge regression is better than our other shrinkage method, the lasso? You can separate your data set into training and test sets, run each model on the training set, and then calculate RMSE or MSE using the test sets. ISLR does this on page 253-255 in case you are curious to see how this is done in R.</p>
<p><br></p>
<p class="comment" , style="font-style:normal">
<strong>Question 6</strong>: What are the coefficient values when you run a Lasso regression?
</p>
<hr />
<p>Website created and maintained by <a href="https://nbrazil.faculty.ucdavis.edu/">Noli Brazil</a></p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>


</body>
</html>
