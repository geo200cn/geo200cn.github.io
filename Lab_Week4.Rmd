---
title: "Lab Week 4"
author: "Kenji Tomari"
output: 
  html_document:
    theme: readable
    toc: true
    toc_depth: 3
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Supplemental Tips

For many folks, exploring a new package is quite challenging. There are tons of online resources for the more popular packages, like `{sf}`. There are few for others. In any case, most packages usually have starting place in their "vignette." If you go to rdocumentation.org and look up a package, you can usually scroll down to where the vignettes are listed. Unfortunately, these are sometimes out of date. You actually have access to all the vignettes for the packages you have installed right from RStudio/R.

Go to your console and type the following in order to get a list of available vignettes.

```{r eval=F}
vignette(package = "sf")
```

Once you've picked a vignette topic, try:

```{r eval=F}
vignette(topic = "sf1", package = "sf")
```

This week you'll use the spatial points package known as `{spatstat}`. You might want to check out their "getting started" vignette.

```{r eval=F}
vignette(topic = "getstart", package = "spatstat")
```


# Part 1 - {sf}

This section summarizes [Mapping using the sf package](https://geo200cn.github.io/spatialsf.html), focusing on the code necessary to complete Assignment 4.

```{r message = F, warning = F, error = F}
library(tidyverse)
library(sf)
library(tmap)
```

## a. read data (& data exploration)

```{r}
# spatial data
smt <- st_read("sacmetrotract.shp")
```

```{r}
# non-spatial data
smtw <- read_csv("sacmetrotractwhite.csv")
```


```{r}
# Just look at non-spatial data from this spatial data set.
smt %>%
  # this will remove the geometry/spatial data (NOTE: I do not save this.)
  st_set_geometry(NULL) %>%
  head()
```

```{r}
# Just look at non-spatial data from this spatial data set.
smt %>%
  # this will remove the geometry/spatial data (NOTE: I do not save this.)
  st_set_geometry(NULL) %>%
  str()
```

```{r}
head(smtw)
```

## b. merge/join

```{r}
# a "merge" or "join" of the two data sets.
# make sure you select the right "by" value... ie the common column in both
# data.frames.
smt <- smt %>%
  left_join(smtw, by = "GEOID")
```

Why the warning message? Because GEOID is considered a factor in the `smt` df, but not in `smtw`.

## c. creating a variable

Let's create percent non-hispanic white as a column

```{r}
smt <- smt %>%
  mutate(pwh = nhwhite/tpopr)
```

## d. 5-quantile choropleth map

You can use a number of packages to map things in R. Here Noli has us use `{tmap}`. Read more [here](https://www.rdocumentation.org/packages/tmap). Also, they provide this bit on [getting started](https://www.rdocumentation.org/packages/tmap/versions/3.0/vignettes/tmap-getstarted.Rmd).

```{r}
# tmap
tm_shape(smt) +
  tm_polygons(col = "pwh", 
              style = "quantile", 
              n=5)
```

FYI:

> The "quantile" style provides quantile breaks. [Read More.](https://www.rdocumentation.org/packages/classInt/versions/0.1-7/topics/classIntervals)

```{r}
# ggplot2
smt %>%
  # create new column for intervals
  mutate(cuts = cut_number(pwh, n=5)) %>%
  # make plot
  ggplot(data = .) +
  # add spatial geometry, with fill by new "cuts" column
  # make borders grey with size = 0.1
  geom_sf(mapping = aes(fill = cuts), color = "grey", size = 0.1) +
  # fill colors using the "color brewer"
  # set NA value to charcoal color.
  # add title for legend
  scale_fill_brewer(type="seq",
                    palette = "YlOrBr",
                    na.value = '#333333',
                    guide = guide_legend(title = "percent white")) +
  # add title
  labs(title = "5-Quantile Map") +
  # set background to black and white
  theme_bw()
```

## e-1. 10 Quantile Map

FYI, the fine folks at colorbrewer strongly advise against more than 9 colors for choropleth maps. Check them out [here](https://colorbrewer2.org/).

```{r}
# tmap
tm_shape(smt) +
  tm_polygons(col = "pwh", style = "quantile", n=10)
```


```{r}
# ggplot2
smt %>%
  mutate(cuts = cut_number(pwh, n=10)) %>%
  ggplot(data = .) +
  geom_sf(mapping = aes(fill = cuts), color = "grey", size = 0.1) +
  scale_fill_manual(
    # fill colors
    values =
      c('#ffffe5',
        '#fff7bc',
        '#fee391',
        '#fec44f',
        '#fe9929',
        '#ec7014',
        '#cc4c02',
        '#993404',
        '#662506',
        '#481a04'),
    na.value = '#333333',
    guide = guide_legend(title = "percent white")
  ) +
  labs(title = "Decile Map") +
  theme_bw()
```


## e-2. 5 Equal Interval Map

> The "equal" style divides the range of the variable into n parts. [Read More.](https://www.rdocumentation.org/packages/classInt/versions/0.1-7/topics/classIntervals)

```{r}
# tmap
tm_shape(smt) +
  tm_polygons(col = "pwh", style = "equal", n=5)
```

Before, we used `cut_number`, but now we'll use `cut_interval`.

```{r}
# ggplot2
smt %>%
  mutate(cuts = cut_interval(pwh, n=5)) %>%
  # make a plot
  ggplot(data = .) +
  # make geometry/polygons
  geom_sf(mapping = aes(fill = cuts), color = "grey", size = 0.1) +
  # fill colors
  scale_fill_brewer(type="seq",
                    palette = "YlOrBr",
                    na.value = '#333333',
                    guide = guide_legend(title = "percent white")) +
  # title
  labs(title = "5 Equal Interval Map") +
  # make background black and white.
  theme_bw()
```

# Part 2 - Point Pattern Analysis

## Notes on Loading Packages/Data

Originally, this lab guide was written by Professor Hijmans and he pulls in data that he set up in a package he calls `rspatial`. So, he has folks use the package `devtools` to pull in this data. However, devtools has a number of dependencies (other packages that are part of it) that may present some challenges to downloading it. So, for this lab, skip the code that runs `devtools::install_github('rspatial/rspatial')` and instead use the data we provide to you on Canvas. You can use this code to load in the data.

```{r eval=F}
city <- rgdal::readOGR("assignment4_city.shp")
crime <- rgdal::readOGR("assignment4_crime.shp")
```

## Notes on Material

### Overall Density

*Supplemental*

*Note* in the lab guide on "Overall Density," it says that `area` measures the city in feet squared. This is not because of the function itself, but a product of the CRS. Note how it says "+units=us-ft" when you run `crs(city)`. In order to change this, you need to "transform" the CRS. You could do this, for instance, by using `sp::spTransform(city, CRS=CRS("+init=epsg:3857"))` which will convert the CRS of `city` to EPSG 3857. Also, you could do a CRS transformation in `{sf}` as well. Assuming you're beginning with an sf object, the appropriate code would be: `st_transform(city, 3857)`.

Also take note that both the `city` and `crime` data have to have the same CRS! You can test this pretty easily like this:

```{r eval=F}
sp::identicalCRS(city, crime)
```

Keep in mind that EPSG 3857 may not be the CRS you actually want to work with. You may instead choose to use a more California-centric CRS like NAD83 California Albers, EPSG 3310. 


### QUESTION 1

Explain why a VMR greater than 1 indicates spatial clustering. 

OSU p 130. Also read a summary of Poisson on BBR p 228 and OSU 142-3.

### Hypothesis Testing

*Supplemental*

Note, we use a chi-squared test (and not a t-test) because a frequency table of quadrats with events uses categorical variables, and not continous variables. Whereas, when we were examining rainfall or asset prices of houses in Assignment 2, the data were were testing was (evidently) continous (i.e. in inches or dollars per sq ft.). In other words, points/events per quadrat are discrete values (eg. 3 events some quadrat), and the frequency table is composed of categorical variables (eg. how many quadrats had exactly 3 events).

### QUESTION 2

Question 2: What does the VMR score combined with the chi-square test tell us about the point pattern? 

See OSU p 142.

### Kernel Density

*Supplemental*

Note: chapter 5 doesn't go into to KDE very much, but it is related to Quadrats, because its looking at density/1st order effects.

### QUESTION 3

What do the Clark Evans test results tell us about the point pattern? Explain why an R less than 1 indicates spatial clustering? 

See OSU p 143-4.

### Distance Functions (F, G, K, & L)

*Supplemental*

Note, the K function is not related to Kernel Density Estimation (KDE). The former is a distance function, and the latter is a density function.

Also, interpreting the plot of the K function is quite challenging. If you look at `K$r` and `K$theo` you can quickly deduce that the relationship between distance, `r`, and the expected value `theo` is described on page 146 in OSU in equation 5.13.

### QUESTION 4

Calculate the F and G functions. Interpret the results. 

See OSU p 134 for information about comparing G and F functions.